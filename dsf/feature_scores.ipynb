{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed2ff2c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adult\n",
      "[9.38522692e-02 0.00000000e+00 3.83311415e-03 1.05216119e-02\n",
      " 1.02228721e-02 7.23444040e-03 2.59079021e-03 0.00000000e+00\n",
      " 4.95209759e-03 3.59536539e-02 2.52651830e-02 1.51311745e-03\n",
      " 9.91172783e-03 9.87822748e-03 1.25643347e-02 0.00000000e+00\n",
      " 5.09179469e-04 7.49263753e-03 0.00000000e+00 1.11986371e-03\n",
      " 1.41327857e-02 4.24001879e-03 1.12664787e-04 6.97334627e-03\n",
      " 0.00000000e+00 7.49367155e-04 7.80903469e-02 1.44384741e-01\n",
      " 1.33040061e-02 9.26007850e-02 6.73173941e-03 3.64499305e-04\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 6.22195332e-03\n",
      " 2.86125004e-02 4.34751307e-03 2.75823440e-02 1.72109759e-02\n",
      " 1.14701808e-02 6.57170305e-03 8.05401830e-03 6.11903282e-03\n",
      " 5.05694139e-03 7.80242472e-03 0.00000000e+00 8.83028306e-03\n",
      " 6.64493825e-03 5.60260772e-02 1.04148488e-01 2.42904312e-02\n",
      " 4.63969769e-03 1.94982389e-02 8.76054264e-03 0.00000000e+00\n",
      " 1.81324675e-03 0.00000000e+00 1.01878419e-02 4.01649081e-02\n",
      " 3.36525090e-02 8.65535565e-02 3.64912224e-02 5.82834595e-02]\n"
     ]
    }
   ],
   "source": [
    "# %% imports\n",
    "\n",
    "import os\n",
    "import json\n",
    "import subprocess\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "from sklearn.utils.estimator_checks import check_estimator\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "import ReadData as ReadData\n",
    "import cString2json as cString2json\n",
    "import json2graphNoLeafEdgesWithSplitValues as json2graphNoLeafEdgesWithSplitValues\n",
    "from fitModels import fitModels\n",
    "import DecisionSnippetFeatures as DecisionSnippetFeatures\n",
    "import pruning\n",
    "import Forest\n",
    "import datetime\n",
    "from util import writeToReport\n",
    "import numpy as np\n",
    "# %% Parameters. \n",
    "\n",
    "dataPath = \"../data/\"\n",
    "forestsPath = \"../tmp/forests/\"\n",
    "snippetsPath = \"../tmp/snippets/\"\n",
    "resultsPath = \"../tmp/results/\"\n",
    "reportsPath = \"../tmp/reports/\"\n",
    "\n",
    "# current valid options are ['sensorless', 'satlog', 'mnist', 'magic', 'spambase', 'letter', 'bank', 'adult', 'drinking']\n",
    "\n",
    "#dataset = sys.argv[1]\n",
    "dataset = 'adult'\n",
    "print(dataset)\n",
    "#dataSet = 'satlog'\n",
    "# dataSet = 'adult'\n",
    "# dataSet = 'drinking'\n",
    "\n",
    "# possible forest_types ['RF', 'DT', 'ET']\n",
    "forest_types = ['RF']\n",
    "forest_depths = [5]\n",
    "sigma_values = [0.3]\n",
    "forest_sizes = [25]\n",
    "maxPatternSize = 1\n",
    "#minThreshold = int(sys.argv[2])\n",
    "#maxThreshold = int(sys.argv[3])\n",
    "\n",
    "minThreshold = 1\n",
    "maxThreshold = 1\n",
    "\n",
    "#edge_thresholds = [1.0,0.975,0.95,0.925,0.9,0.85,0.8,0.7,0.6]\n",
    "edge_thresholds = [1.0]\n",
    "\n",
    "#mode = int(sys.argv[2])\n",
    "mode = 2\n",
    "if (mode == 1):\n",
    "    \n",
    "    run_fit_models = True\n",
    "    run_mining = True\n",
    "    run_training = False\n",
    "    run_eval = False\n",
    "    \n",
    "if (mode == 2):\n",
    "    \n",
    "    run_fit_models = False\n",
    "    run_mining = False\n",
    "    run_training = True\n",
    "    run_eval = False\n",
    "    \n",
    "#patterns_thresholds = [1,2,3]\n",
    "\n",
    "scoring_function = 'accuracy'\n",
    "\n",
    "# learners that are to be used on top of Decision Snippet Features\n",
    "learners = {'NB': MultinomialNB,\n",
    "            'SVM': LinearSVC,\n",
    "            'LR': LogisticRegression}\n",
    "\n",
    "#learners = {'NB': MultinomialNB}\n",
    "\n",
    "# specify parameters that are given at initialization\n",
    "learners_parameters = {'NB': {},\n",
    "                       'SVM': {'max_iter': 10000},\n",
    "                       'LR': {'max_iter': 10000}}\n",
    "\n",
    "#learners_parameters = {'NB': {}}\n",
    "\n",
    "\n",
    "# for quick debugging, let the whole thing run once. Afterwards, you may deactivate individual steps\n",
    "# each step stores its output for the subsequent step(s) to process\n",
    "\n",
    "verbose = True\n",
    "\n",
    "fitting_models_time = datetime.timedelta()\n",
    "pruning_time = datetime.timedelta()\n",
    "\n",
    "\n",
    "\n",
    "# %% load data\n",
    "\n",
    "X_train, Y_train = ReadData.readData(dataset, 'train', dataPath)\n",
    "X_test, Y_test = ReadData.readData(dataset, 'test', dataPath)\n",
    "X = X_train\n",
    "\n",
    "arr = mutual_info_classif(X_train,Y_train)\n",
    "print(arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6206c4ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 26, Value: 10, Errors count: 5316\n",
      "Feature: 26, Value: 11, Errors count: 5345\n",
      "Feature: 26, Value: 12, Errors count: 5349\n",
      "Feature: 27, Value: 0, Errors count: 3958\n",
      "Feature: 29, Value: 0, Errors count: 5385\n",
      "Feature: 50, Value: 0, Errors count: 4383\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "    \n",
    "'''\n",
    "for feature in range(len(X_train[0])):\n",
    "    s = set()\n",
    "    for x in X_train:\n",
    "        s.add(x[feature])\n",
    "'''\n",
    "Y_train_1 = sum(Y_train)\n",
    "Y_train_0 = len(Y_train) - Y_train_1\n",
    "\n",
    "index = 0        \n",
    "    \n",
    "for feature in range(len(X_train[0])):\n",
    "    #print('Feature: ' + str(feature))\n",
    "    \n",
    "    values = set(X_train[:,feature])\n",
    "    for value in values:\n",
    "        #print('Value: ' + str(value))\n",
    "        #print(values)\n",
    "        class_counts = defaultdict(int)\n",
    "        for sample, y in zip(X_train, Y_train):\n",
    "            if(sample[feature] <= value):\n",
    "                class_counts[y] += 1\n",
    "        #print(class_counts) \n",
    "        if (class_counts[0] <= class_counts[1]):\n",
    "            index = 1\n",
    "        else:\n",
    "            index = 0\n",
    "            \n",
    "        majority = class_counts[index]\n",
    "        minority = class_counts[1-index]\n",
    "            \n",
    "        if (index == 1):\n",
    "            sub_error = Y_train_1 - majority\n",
    "        else:\n",
    "            sub_error = Y_train_0 - majority\n",
    "        errors_count = minority + sub_error \n",
    "        #print(errors_count)\n",
    "        if (errors_count < 5500):\n",
    "            print('Feature: ' + str(feature) + ', Value: ' + str(value) + ', Errors count: ' + str(errors_count))\n",
    "                \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db773756",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93a7795",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
