Forest Size, Forest Depth, Patterns threshold, Edges Threshold, Learner, Train Accuracy, Test Accuracy, Test Accuracy (gain), F1_macro, F1_macro (gain), F1_micro, ROC_AUC, ROC_AUC (gain), Patterns Count, Patterns Ratio, Nodes Count, Nodes Ratio, Training Time, Pruning Time
,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,
16,5,1,0.95,LogisticRegression(max_iter=10000),0.823,0.811,-0.189,0.661,-0.339,0.811,0,-1,176,176,254,176,0:00:06.647663,0:00:00
,,,,,,,,,,,,,,,,,,
16,5,1,0.9,LogisticRegression(max_iter=10000),0.822,0.81,-0.19,0.656,-0.344,0.81,0,-1,83,83,216,83,0:00:02.639480,0:00:00
,,,,,,,,,,,,,,,,,,
16,5,1,0.85,LogisticRegression(max_iter=10000),0.821,0.811,-0.189,0.657,-0.343,0.811,0,-1,21,21,178,21,0:00:00.367117,0:00:00
,,,,,,,,,,,,,,,,,,
16,5,1,0.8,LogisticRegression(max_iter=10000),0.779,0.779,-0.221,0.438,-0.562,0.779,0,-1,3,3,144,3,0:00:00.080964,0:00:00
,,,,,,,,,,,,,,,,,,
16,5,1,0.75,LogisticRegression(max_iter=10000),0.779,0.779,-0.221,0.438,-0.562,0.779,0,-1,3,3,125,3,0:00:00.145176,0:00:00
,,,,,,,,,,,,,,,,,,
16,5,1,0.7,LogisticRegression(max_iter=10000),0.779,0.779,-0.221,0.438,-0.562,0.779,0,-1,1,1,103,1,0:00:00.071145,0:00:00
,,,,,,,,,,,,,,,,,,
16,5,1,0.65,LogisticRegression(max_iter=10000),0.822,0.808,-0.192,0.651,-0.349,0.808,0,-1,81,81,81,81,0:00:02.068877,0:00:00
,,,,,,,,,,,,,,,,,,
16,5,1,0.6,LogisticRegression(max_iter=10000),0.821,0.81,-0.19,0.653,-0.347,0.81,0,-1,54,54,54,54,0:00:00.602821,0:00:00
,,,,,,,,,,,,,,,,,,
16,10,1,0.95,LogisticRegression(max_iter=10000),0.833,0.804,-0.196,0.655,-0.345,0.804,0,-1,1655,1655,3797,1655,0:02:31.668781,0:00:00
,,,,,,,,,,,,,,,,,,
16,10,1,0.9,LogisticRegression(max_iter=10000),0.826,0.811,-0.189,0.664,-0.336,0.811,0,-1,563,563,3372,563,0:00:28.649909,0:00:00
,,,,,,,,,,,,,,,,,,
16,10,1,0.85,LogisticRegression(max_iter=10000),0.819,0.811,-0.189,0.657,-0.343,0.811,0,-1,47,47,2931,47,0:00:00.417135,0:00:00
,,,,,,,,,,,,,,,,,,
16,10,1,0.8,LogisticRegression(max_iter=10000),0.82,0.81,-0.19,0.655,-0.345,0.81,0,-1,25,25,2557,25,0:00:00.137048,0:00:00
,,,,,,,,,,,,,,,,,,
16,10,1,0.75,LogisticRegression(max_iter=10000),0.779,0.779,-0.221,0.438,-0.562,0.779,0,-1,2,2,2161,2,0:00:00.048021,0:00:00
,,,,,,,,,,,,,,,,,,
16,10,1,0.7,LogisticRegression(max_iter=10000),0.779,0.779,-0.221,0.438,-0.562,0.779,0,-1,2,2,1711,2,0:00:00.053836,0:00:00
,,,,,,,,,,,,,,,,,,
16,10,1,0.65,LogisticRegression(max_iter=10000),0.83,0.806,-0.194,0.655,-0.345,0.806,0,-1,1227,1227,1227,1227,0:01:36.487949,0:00:00
,,,,,,,,,,,,,,,,,,
16,10,1,0.6,LogisticRegression(max_iter=10000),0.828,0.808,-0.192,0.657,-0.343,0.808,0,-1,951,951,951,951,0:01:02.513945,0:00:00
,,,,,,,,,,,,,,,,,,
16,15,1,0.95,LogisticRegression(max_iter=10000),0.85,0.789,-0.211,0.639,-0.361,0.789,0,-1,3787,3787,12537,3787,0:09:07.623053,0:00:00
,,,,,,,,,,,,,,,,,,
16,15,1,0.9,LogisticRegression(max_iter=10000),0.829,0.805,-0.195,0.65,-0.35,0.805,0,-1,1037,1037,11296,1037,0:01:14.698699,0:00:00
,,,,,,,,,,,,,,,,,,
16,15,1,0.85,LogisticRegression(max_iter=10000),0.822,0.81,-0.19,0.658,-0.342,0.81,0,-1,191,191,10081,191,0:00:05.497018,0:00:00
,,,,,,,,,,,,,,,,,,
16,15,1,0.8,LogisticRegression(max_iter=10000),0.818,0.809,-0.191,0.646,-0.354,0.809,0,-1,26,26,9099,26,0:00:00.107987,0:00:00
,,,,,,,,,,,,,,,,,,
16,15,1,0.75,LogisticRegression(max_iter=10000),0.779,0.779,-0.221,0.438,-0.562,0.779,0,-1,4,4,7869,4,0:00:00.045725,0:00:00
,,,,,,,,,,,,,,,,,,
16,15,1,0.7,LogisticRegression(max_iter=10000),0.779,0.779,-0.221,0.438,-0.562,0.779,0,-1,4,4,6343,4,0:00:00.048942,0:00:00
,,,,,,,,,,,,,,,,,,
16,15,1,0.65,LogisticRegression(max_iter=10000),0.856,0.786,-0.214,0.64,-0.36,0.786,0,-1,4441,4441,4441,4441,0:11:34.504280,0:00:00
,,,,,,,,,,,,,,,,,,
16,15,1,0.6,LogisticRegression(max_iter=10000),0.849,0.79,-0.21,0.641,-0.359,0.79,0,-1,3622,3622,3622,3622,0:08:14.664559,0:00:00
,,,,,,,,,,,,,,,,,,
32,5,1,0.95,LogisticRegression(max_iter=10000),0.825,0.81,-0.19,0.658,-0.342,0.81,0,-1,386,386,497,386,0:00:23.015099,0:00:00
,,,,,,,,,,,,,,,,,,
32,5,1,0.9,LogisticRegression(max_iter=10000),0.823,0.811,-0.189,0.661,-0.339,0.811,0,-1,168,168,426,168,0:00:05.208494,0:00:00
,,,,,,,,,,,,,,,,,,
32,5,1,0.85,LogisticRegression(max_iter=10000),0.821,0.809,-0.191,0.654,-0.346,0.809,0,-1,47,47,366,47,0:00:00.992474,0:00:00
,,,,,,,,,,,,,,,,,,
32,5,1,0.8,LogisticRegression(max_iter=10000),0.79,0.783,-0.217,0.55,-0.45,0.783,0,-1,7,7,308,7,0:00:00.037683,0:00:00
,,,,,,,,,,,,,,,,,,
32,5,1,0.75,LogisticRegression(max_iter=10000),0.779,0.779,-0.221,0.438,-0.562,0.779,0,-1,3,3,254,3,0:00:00.048865,0:00:00
,,,,,,,,,,,,,,,,,,
32,5,1,0.7,LogisticRegression(max_iter=10000),0.779,0.779,-0.221,0.438,-0.562,0.779,0,-1,3,3,204,3,0:00:00.058494,0:00:00
,,,,,,,,,,,,,,,,,,
32,5,1,0.65,LogisticRegression(max_iter=10000),0.822,0.809,-0.191,0.652,-0.348,0.809,0,-1,157,157,157,157,0:00:04.600318,0:00:00
,,,,,,,,,,,,,,,,,,
32,5,1,0.6,LogisticRegression(max_iter=10000),0.821,0.81,-0.19,0.652,-0.348,0.81,0,-1,115,115,115,115,0:00:03.741650,0:00:00
,,,,,,,,,,,,,,,,,,
32,10,1,0.95,LogisticRegression(max_iter=10000),0.851,0.788,-0.212,0.642,-0.358,0.788,0,-1,3586,3586,7151,3586,0:08:32.584550,0:00:00
,,,,,,,,,,,,,,,,,,
32,10,1,0.9,LogisticRegression(max_iter=10000),0.83,0.808,-0.192,0.656,-0.344,0.808,0,-1,901,901,6322,901,0:00:59.730741,0:00:00
,,,,,,,,,,,,,,,,,,
32,10,1,0.85,LogisticRegression(max_iter=10000),0.823,0.811,-0.189,0.661,-0.339,0.811,0,-1,111,111,5496,111,0:00:03.521800,0:00:00
,,,,,,,,,,,,,,,,,,
32,10,1,0.8,LogisticRegression(max_iter=10000),0.808,0.804,-0.196,0.64,-0.36,0.804,0,-1,29,29,4818,29,0:00:00.247329,0:00:00
,,,,,,,,,,,,,,,,,,
32,10,1,0.75,LogisticRegression(max_iter=10000),0.79,0.788,-0.212,0.572,-0.428,0.788,0,-1,11,11,4133,11,0:00:00.062334,0:00:00
,,,,,,,,,,,,,,,,,,
32,10,1,0.7,LogisticRegression(max_iter=10000),0.79,0.788,-0.212,0.572,-0.428,0.788,0,-1,11,11,3318,11,0:00:00.060249,0:00:00
,,,,,,,,,,,,,,,,,,
32,10,1,0.65,LogisticRegression(max_iter=10000),0.84,0.799,-0.201,0.65,-0.35,0.799,0,-1,2361,2361,2361,2361,0:04:00.959764,0:00:00
,,,,,,,,,,,,,,,,,,
32,10,1,0.6,LogisticRegression(max_iter=10000),0.834,0.806,-0.194,0.658,-0.342,0.806,0,-1,1772,1772,1772,1772,0:02:44.885856,0:00:00
,,,,,,,,,,,,,,,,,,
32,15,1,0.95,LogisticRegression(max_iter=10000),0.86,0.781,-0.219,0.636,-0.364,0.781,0,-1,5093,5093,22861,5093,0:15:48.352017,0:00:00
,,,,,,,,,,,,,,,,,,
32,15,1,0.9,LogisticRegression(max_iter=10000),0.829,0.807,-0.193,0.656,-0.344,0.807,0,-1,857,857,20691,857,0:01:00.946549,0:00:00
,,,,,,,,,,,,,,,,,,
32,15,1,0.85,LogisticRegression(max_iter=10000),0.797,0.796,-0.204,0.598,-0.402,0.796,0,-1,11,11,18298,11,0:00:00.280503,0:00:00
,,,,,,,,,,,,,,,,,,
32,15,1,0.8,LogisticRegression(max_iter=10000),0.778,0.778,-0.222,0.446,-0.554,0.778,0,-1,6,6,16518,6,0:00:00.064394,0:00:00
,,,,,,,,,,,,,,,,,,
32,15,1,0.75,LogisticRegression(max_iter=10000),0.778,0.778,-0.222,0.446,-0.554,0.778,0,-1,5,5,14386,5,0:00:00.067836,0:00:00
,,,,,,,,,,,,,,,,,,
32,15,1,0.7,LogisticRegression(max_iter=10000),0.779,0.779,-0.221,0.438,-0.562,0.779,0,-1,1,1,11633,1,0:00:00.059921,0:00:00
,,,,,,,,,,,,,,,,,,
32,15,1,0.65,LogisticRegression(max_iter=10000),0.883,0.769,-0.231,0.627,-0.373,0.769,0,-1,8265,8265,8265,8265,0:30:43.588577,0:00:00
,,,,,,,,,,,,,,,,,,
32,15,1,0.6,LogisticRegression(max_iter=10000),0.883,0.769,-0.231,0.627,-0.373,0.769,0,-1,8265,8265,6697,8265,0:30:43.588577,0:00:00
,,,,,,,,,,,,,,,,,,
64,5,1,0.95,LogisticRegression(max_iter=10000),0.828,0.808,-0.192,0.658,-0.342,0.808,0,-1,656,656,913,656,0:00:38.442293,0:00:00
,,,,,,,,,,,,,,,,,,
64,5,1,0.9,LogisticRegression(max_iter=10000),0.822,0.807,-0.193,0.649,-0.351,0.807,0,-1,225,225,775,225,0:00:06.643910,0:00:00
,,,,,,,,,,,,,,,,,,
64,5,1,0.85,LogisticRegression(max_iter=10000),0.819,0.809,-0.191,0.644,-0.356,0.809,0,-1,50,50,683,50,0:00:01.152550,0:00:00
,,,,,,,,,,,,,,,,,,
64,5,1,0.8,LogisticRegression(max_iter=10000),0.819,0.809,-0.191,0.643,-0.357,0.809,0,-1,22,22,584,22,0:00:00.133621,0:00:00
,,,,,,,,,,,,,,,,,,
64,5,1,0.75,LogisticRegression(max_iter=10000),0.82,0.811,-0.189,0.646,-0.354,0.811,0,-1,16,16,490,16,0:00:00.091923,0:00:00
,,,,,,,,,,,,,,,,,,
64,5,1,0.7,LogisticRegression(max_iter=10000),0.779,0.779,-0.221,0.438,-0.562,0.779,0,-1,9,9,399,9,0:00:00.077485,0:00:00
,,,,,,,,,,,,,,,,,,
64,5,1,0.65,LogisticRegression(max_iter=10000),0.779,0.779,-0.221,0.438,-0.562,0.779,0,-1,9,9,303,9,0:00:00.078166,0:00:00
,,,,,,,,,,,,,,,,,,
64,5,1,0.6,LogisticRegression(max_iter=10000),0.779,0.779,-0.221,0.438,-0.562,0.779,0,-1,9,9,213,9,0:00:00.078166,0:00:00
,,,,,,,,,,,,,,,,,,
64,10,1,0.95,LogisticRegression(max_iter=10000),0.865,0.78,-0.221,0.637,-0.363,0.78,0,-1,5717,5717,13336,5717,0:17:58.667956,0:00:00
,,,,,,,,,,,,,,,,,,
64,10,1,0.9,LogisticRegression(max_iter=10000),0.831,0.806,-0.194,0.654,-0.346,0.806,0,-1,1239,1239,11794,1239,0:01:44.529375,0:00:00
,,,,,,,,,,,,,,,,,,
64,10,1,0.85,LogisticRegression(max_iter=10000),0.822,0.81,-0.19,0.657,-0.343,0.81,0,-1,118,118,10269,118,0:00:03.472952,0:00:00
,,,,,,,,,,,,,,,,,,
64,10,1,0.8,LogisticRegression(max_iter=10000),0.807,0.804,-0.196,0.636,-0.364,0.804,0,-1,22,22,8968,22,0:00:00.173841,0:00:00
,,,,,,,,,,,,,,,,,,
64,10,1,0.75,LogisticRegression(max_iter=10000),0.779,0.779,-0.221,0.438,-0.562,0.779,0,-1,8,8,7642,8,0:00:00.046189,0:00:00
,,,,,,,,,,,,,,,,,,
64,10,1,0.7,LogisticRegression(max_iter=10000),0.779,0.779,-0.221,0.438,-0.562,0.779,0,-1,7,7,6174,7,0:00:00.042451,0:00:00
,,,,,,,,,,,,,,,,,,
64,10,1,0.65,LogisticRegression(max_iter=10000),0.779,0.779,-0.221,0.438,-0.562,0.779,0,-1,7,7,4450,7,0:00:00.042520,0:00:00
,,,,,,,,,,,,,,,,,,
64,10,1,0.6,LogisticRegression(max_iter=10000),0.779,0.779,-0.221,0.438,-0.562,0.779,0,-1,7,7,3377,7,0:00:00.042520,0:00:00
,,,,,,,,,,,,,,,,,,
64,15,1,0.95,LogisticRegression(max_iter=10000),0.905,0.765,-0.235,0.627,-0.373,0.765,0,-1,11570,11570,41893,11570,0:57:46.875259,0:00:00
,,,,,,,,,,,,,,,,,,
64,15,1,0.9,LogisticRegression(max_iter=10000),0.841,0.799,-0.201,0.652,-0.348,0.799,0,-1,2388,2388,37923,2388,0:05:47.171737,0:00:00
,,,,,,,,,,,,,,,,,,
64,15,1,0.85,LogisticRegression(max_iter=10000),0.825,0.814,-0.186,0.666,-0.334,0.814,0,-1,404,404,33773,404,0:00:23.717196,0:00:00
,,,,,,,,,,,,,,,,,,
64,15,1,0.8,LogisticRegression(max_iter=10000),0.821,0.81,-0.19,0.654,-0.346,0.81,0,-1,104,104,30458,104,0:00:03.359070,0:00:00
,,,,,,,,,,,,,,,,,,
64,15,1,0.75,LogisticRegression(max_iter=10000),0.806,0.802,-0.198,0.636,-0.364,0.802,0,-1,34,34,26738,34,0:00:00.612656,0:00:00
,,,,,,,,,,,,,,,,,,
64,15,1,0.7,LogisticRegression(max_iter=10000),0.799,0.793,-0.207,0.636,-0.364,0.793,0,-1,22,22,21733,22,0:00:00.313728,0:00:00
,,,,,,,,,,,,,,,,,,
64,15,1,0.65,LogisticRegression(max_iter=10000),0.78,0.78,-0.22,0.456,-0.544,0.78,0,-1,19,19,15469,19,0:00:00.370517,0:00:00
,,,,,,,,,,,,,,,,,,
64,15,1,0.6,LogisticRegression(max_iter=10000),0.78,0.78,-0.22,0.456,-0.544,0.78,0,-1,19,19,12745,19,0:00:00.370517,0:00:00
16,5,1,0.55,LogisticRegression(max_iter=10000),0.821,0.809,-0.191,0.652,-0.348,0.809,0,-1.0,32,32.0,32,32.0,0:00:00.195374,0:00:00,

16,10,1,0.55,LogisticRegression(max_iter=10000),0.825,0.809,-0.191,0.658,-0.342,0.809,0,-1.0,545,545.0,545,545.0,0:00:33.106195,0:00:00,

16,15,1,0.55,LogisticRegression(max_iter=10000),0.839,0.799,-0.201,0.646,-0.354,0.799,0,-1.0,2198,2198.0,2198,2198.0,0:03:50.401344,0:00:00,

32,5,1,0.55,LogisticRegression(max_iter=10000),0.819,0.808,-0.192,0.644,-0.356,0.808,0,-1.0,67,67.0,67,67.0,0:00:01.939998,0:00:00,

32,10,1,0.55,LogisticRegression(max_iter=10000),0.828,0.812,-0.188,0.664,-0.336,0.812,0,-1.0,1017,1017.0,1017,1017.0,0:01:16.967773,0:00:00,

32,15,1,0.55,LogisticRegression(max_iter=10000),0.852,0.786,-0.215,0.641,-0.359,0.786,0,-1.0,4102,4102.0,4102,4102.0,0:13:26.042902,0:00:00,

64,5,1,0.55,LogisticRegression(max_iter=10000),0.821,0.808,-0.192,0.651,-0.349,0.808,0,-1.0,117,117.0,117,117.0,0:00:02.921649,0:00:00,

64,10,1,0.55,LogisticRegression(max_iter=10000),0.837,0.797,-0.203,0.65,-0.35,0.797,0,-1.0,1889,1889.0,1889,1889.0,0:03:11.206847,0:00:00,

