,,,,,,,,,,,,,,,,,,
Forest Size, Forest Depth, Patterns threshold, Edges Threshold, Learner, Train Accuracy, Test Accuracy, Test Accuracy (gain), F1_macro, F1_macro (gain), F1_micro, ROC_AUC, ROC_AUC (gain), Patterns Count, Patterns Ratio, Nodes Count, Nodes Ratio, Training Time, Pruning Time
,,,,,,,,,,,,,,,,,,
16,5,1,1,LogisticRegression(max_iter=10000),0.835,0.839,0,0.815,0,0.839,0,0,240,1,240,1,0:00:05.412283,0:00:00
,,,,,,,,,,,,,,,,,,
16,5,1,0.95,LogisticRegression(max_iter=10000),0.831,0.836,-0.002,0.812,-0.003,0.836,0,0,197,0.821,197,0.821,0:00:05.043466,0:00:00
,,,,,,,,,,,,,,,,,,
16,5,1,0.9,LogisticRegression(max_iter=10000),0.829,0.833,-0.006,0.808,-0.007,0.833,0,0,178,0.742,178,0.742,0:00:03.231518,0:00:00
,,,,,,,,,,,,,,,,,,
16,5,1,0.85,LogisticRegression(max_iter=10000),0.829,0.832,-0.007,0.806,-0.009,0.832,0,0,161,0.671,161,0.671,0:00:02.829777,0:00:00
,,,,,,,,,,,,,,,,,,
16,5,1,0.8,LogisticRegression(max_iter=10000),0.827,0.827,-0.012,0.801,-0.014,0.827,0,0,145,0.604,145,0.604,0:00:01.947849,0:00:00
,,,,,,,,,,,,,,,,,,
16,5,1,0.75,LogisticRegression(max_iter=10000),0.827,0.826,-0.013,0.8,-0.015,0.826,0,0,126,0.525,126,0.525,0:00:01.906878,0:00:00
,,,,,,,,,,,,,,,,,,
16,5,1,0.7,LogisticRegression(max_iter=10000),0.825,0.829,-0.009,0.804,-0.011,0.829,0,0,103,0.429,103,0.429,0:00:01.282248,0:00:00
,,,,,,,,,,,,,,,,,,
16,5,1,0.65,LogisticRegression(max_iter=10000),0.823,0.825,-0.014,0.799,-0.016,0.825,0,0,83,0.346,83,0.346,0:00:00.975465,0:00:00
,,,,,,,,,,,,,,,,,,
16,5,1,0.6,LogisticRegression(max_iter=10000),0.819,0.821,-0.018,0.795,-0.02,0.821,0,0,54,0.225,54,0.225,0:00:00.583780,0:00:00
,,,,,,,,,,,,,,,,,,
16,10,1,1,LogisticRegression(max_iter=10000),0.852,0.832,0,0.808,0,0.832,0,0,992,1,992,1,0:00:32.286948,0:00:00
,,,,,,,,,,,,,,,,,,
16,10,1,0.95,LogisticRegression(max_iter=10000),0.849,0.829,-0.003,0.804,-0.003,0.829,0,0,917,0.924,917,0.924,0:00:28.888943,0:00:00
,,,,,,,,,,,,,,,,,,
16,10,1,0.9,LogisticRegression(max_iter=10000),0.849,0.832,0,0.808,0.001,0.832,0,0,859,0.866,859,0.866,0:00:27.731187,0:00:00
,,,,,,,,,,,,,,,,,,
16,10,1,0.85,LogisticRegression(max_iter=10000),0.848,0.833,0.001,0.809,0.002,0.833,0,0,794,0.8,794,0.8,0:00:25.752746,0:00:00
,,,,,,,,,,,,,,,,,,
16,10,1,0.8,LogisticRegression(max_iter=10000),0.846,0.834,0.002,0.811,0.004,0.834,0,0,732,0.738,732,0.738,0:00:22.277899,0:00:00
,,,,,,,,,,,,,,,,,,
16,10,1,0.75,LogisticRegression(max_iter=10000),0.846,0.835,0.003,0.812,0.004,0.835,0,0,672,0.677,672,0.677,0:00:16.653843,0:00:00
,,,,,,,,,,,,,,,,,,
16,10,1,0.7,LogisticRegression(max_iter=10000),0.845,0.835,0.003,0.812,0.004,0.835,0,0,582,0.587,582,0.587,0:00:18.084501,0:00:00
,,,,,,,,,,,,,,,,,,
16,10,1,0.65,LogisticRegression(max_iter=10000),0.843,0.842,0.01,0.818,0.011,0.842,0,0,462,0.466,462,0.466,0:00:14.137963,0:00:00
,,,,,,,,,,,,,,,,,,
16,10,1,0.6,LogisticRegression(max_iter=10000),0.842,0.841,0.009,0.818,0.01,0.841,0,0,378,0.381,378,0.381,0:00:09.604050,0:00:00
,,,,,,,,,,,,,,,,,,
16,15,1,1,LogisticRegression(max_iter=10000),0.853,0.827,0,0.802,0,0.827,0,0,1192,1,1192,1,0:00:51.321072,0:00:00
,,,,,,,,,,,,,,,,,,
16,15,1,0.95,LogisticRegression(max_iter=10000),0.853,0.829,0.002,0.804,0.002,0.829,0,0,1107,0.929,1107,0.929,0:00:40.161205,0:00:00
,,,,,,,,,,,,,,,,,,
16,15,1,0.9,LogisticRegression(max_iter=10000),0.851,0.832,0.005,0.808,0.006,0.832,0,0,1048,0.879,1048,0.879,0:00:38.772022,0:00:00
,,,,,,,,,,,,,,,,,,
16,15,1,0.85,LogisticRegression(max_iter=10000),0.851,0.831,0.003,0.807,0.004,0.831,0,0,999,0.838,999,0.838,0:00:37.510121,0:00:00
,,,,,,,,,,,,,,,,,,
16,15,1,0.8,LogisticRegression(max_iter=10000),0.85,0.832,0.005,0.809,0.006,0.832,0,0,956,0.802,956,0.802,0:00:30.584458,0:00:00
,,,,,,,,,,,,,,,,,,
16,15,1,0.75,LogisticRegression(max_iter=10000),0.85,0.836,0.008,0.812,0.01,0.836,0,0,907,0.761,907,0.761,0:00:33.854752,0:00:00
,,,,,,,,,,,,,,,,,,
16,15,1,0.7,LogisticRegression(max_iter=10000),0.849,0.835,0.008,0.812,0.01,0.835,0,0,826,0.693,826,0.693,0:00:27.999219,0:00:00
,,,,,,,,,,,,,,,,,,
16,15,1,0.65,LogisticRegression(max_iter=10000),0.849,0.836,0.008,0.813,0.01,0.836,0,0,699,0.586,699,0.586,0:00:23.502821,0:00:00
,,,,,,,,,,,,,,,,,,
16,15,1,0.6,LogisticRegression(max_iter=10000),0.847,0.841,0.014,0.819,0.017,0.841,0,0,630,0.529,630,0.529,0:00:15.265832,0:00:00
,,,,,,,,,,,,,,,,,,
32,5,1,1,LogisticRegression(max_iter=10000),0.839,0.837,0,0.813,0,0.837,0,0,367,1,367,1,0:00:08.214639,0:00:00
,,,,,,,,,,,,,,,,,,
32,5,1,0.95,LogisticRegression(max_iter=10000),0.84,0.838,0.001,0.814,0.001,0.838,0,0,321,0.875,321,0.875,0:00:06.642825,0:00:00
,,,,,,,,,,,,,,,,,,
32,5,1,0.9,LogisticRegression(max_iter=10000),0.84,0.838,0.001,0.814,0.001,0.838,0,0,288,0.785,288,0.785,0:00:05.411199,0:00:00
,,,,,,,,,,,,,,,,,,
32,5,1,0.85,LogisticRegression(max_iter=10000),0.835,0.836,-0.001,0.811,-0.001,0.836,0,0,259,0.706,259,0.706,0:00:04.736195,0:00:00
,,,,,,,,,,,,,,,,,,
32,5,1,0.8,LogisticRegression(max_iter=10000),0.835,0.837,0,0.813,0,0.837,0,0,234,0.638,234,0.638,0:00:03.608302,0:00:00
,,,,,,,,,,,,,,,,,,
32,5,1,0.75,LogisticRegression(max_iter=10000),0.834,0.838,0.001,0.813,0.001,0.838,0,0,203,0.553,203,0.553,0:00:03.018767,0:00:00
,,,,,,,,,,,,,,,,,,
32,5,1,0.7,LogisticRegression(max_iter=10000),0.832,0.835,-0.001,0.811,-0.002,0.835,0,0,172,0.469,172,0.469,0:00:02.233488,0:00:00
,,,,,,,,,,,,,,,,,,
32,5,1,0.65,LogisticRegression(max_iter=10000),0.827,0.83,-0.007,0.805,-0.008,0.83,0,0,128,0.349,128,0.349,0:00:01.690348,0:00:00
,,,,,,,,,,,,,,,,,,
32,5,1,0.6,LogisticRegression(max_iter=10000),0.821,0.823,-0.013,0.796,-0.017,0.823,0,0,102,0.278,102,0.278,0:00:01.115154,0:00:00
,,,,,,,,,,,,,,,,,,
32,10,1,1,LogisticRegression(max_iter=10000),0.852,0.828,0,0.803,0,0.828,0,0,1235,1,1235,1,0:00:47.331764,0:00:00
,,,,,,,,,,,,,,,,,,
32,10,1,0.95,LogisticRegression(max_iter=10000),0.85,0.826,-0.001,0.801,-0.002,0.826,0,0,1142,0.925,1142,0.925,0:00:41.180128,0:00:00
,,,,,,,,,,,,,,,,,,
32,10,1,0.9,LogisticRegression(max_iter=10000),0.85,0.826,-0.001,0.801,-0.002,0.826,0,0,1073,0.869,1073,0.869,0:00:39.553860,0:00:00
,,,,,,,,,,,,,,,,,,
32,10,1,0.85,LogisticRegression(max_iter=10000),0.85,0.828,0.001,0.804,0.001,0.828,0,0,987,0.799,987,0.799,0:00:36.292402,0:00:00
,,,,,,,,,,,,,,,,,,
32,10,1,0.8,LogisticRegression(max_iter=10000),0.849,0.83,0.003,0.806,0.003,0.83,0,0,936,0.758,936,0.758,0:00:32.890848,0:00:00
,,,,,,,,,,,,,,,,,,
32,10,1,0.75,LogisticRegression(max_iter=10000),0.847,0.831,0.003,0.807,0.003,0.831,0,0,858,0.695,858,0.695,0:00:27.642650,0:00:00
,,,,,,,,,,,,,,,,,,
32,10,1,0.7,LogisticRegression(max_iter=10000),0.848,0.833,0.005,0.809,0.006,0.833,0,0,770,0.623,770,0.623,0:00:24.537531,0:00:00
,,,,,,,,,,,,,,,,,,
32,10,1,0.65,LogisticRegression(max_iter=10000),0.846,0.835,0.007,0.811,0.008,0.835,0,0,634,0.513,634,0.513,0:00:15.141099,0:00:00
,,,,,,,,,,,,,,,,,,
32,10,1,0.6,LogisticRegression(max_iter=10000),0.845,0.836,0.009,0.813,0.01,0.836,0,0,557,0.451,557,0.451,0:00:12.878290,0:00:00
,,,,,,,,,,,,,,,,,,
32,15,1,1,LogisticRegression(max_iter=10000),0.855,0.826,0,0.801,0,0.826,0,0,1361,1,1361,1,0:00:56.871782,0:00:00
,,,,,,,,,,,,,,,,,,
32,15,1,0.95,LogisticRegression(max_iter=10000),0.854,0.827,0.001,0.802,0.001,0.827,0,0,1278,0.939,1278,0.939,0:00:53.446476,0:00:00
,,,,,,,,,,,,,,,,,,
32,15,1,0.9,LogisticRegression(max_iter=10000),0.853,0.827,0.001,0.803,0.002,0.827,0,0,1225,0.9,1225,0.9,0:00:46.730001,0:00:00
,,,,,,,,,,,,,,,,,,
32,15,1,0.85,LogisticRegression(max_iter=10000),0.852,0.827,0.001,0.802,0.001,0.827,0,0,1168,0.858,1168,0.858,0:00:44.100006,0:00:00
,,,,,,,,,,,,,,,,,,
32,15,1,0.8,LogisticRegression(max_iter=10000),0.853,0.829,0.003,0.805,0.004,0.829,0,0,1129,0.83,1129,0.83,0:00:40.140030,0:00:00
,,,,,,,,,,,,,,,,,,
32,15,1,0.75,LogisticRegression(max_iter=10000),0.852,0.828,0.002,0.804,0.003,0.828,0,0,1078,0.792,1078,0.792,0:00:39.004134,0:00:00
,,,,,,,,,,,,,,,,,,
32,15,1,0.7,LogisticRegression(max_iter=10000),0.851,0.829,0.003,0.805,0.004,0.829,0,0,1006,0.739,1006,0.739,0:00:48.657566,0:00:00
,,,,,,,,,,,,,,,,,,
32,15,1,0.65,LogisticRegression(max_iter=10000),0.849,0.834,0.008,0.81,0.009,0.834,0,0,874,0.642,874,0.642,0:00:33.629767,0:00:00
,,,,,,,,,,,,,,,,,,
32,15,1,0.6,LogisticRegression(max_iter=10000),0.848,0.836,0.01,0.813,0.012,0.836,0,0,832,0.611,832,0.611,0:00:31.573096,0:00:00
,,,,,,,,,,,,,,,,,,
64,5,1,1,LogisticRegression(max_iter=10000),0.843,0.836,0,0.813,0,0.836,0,0,588,1,588,1,0:00:15.670676,0:00:00
,,,,,,,,,,,,,,,,,,
64,5,1,0.95,LogisticRegression(max_iter=10000),0.841,0.835,-0.001,0.811,-0.002,0.835,0,0,526,0.895,526,0.895,0:00:13.796543,0:00:00
,,,,,,,,,,,,,,,,,,
64,5,1,0.9,LogisticRegression(max_iter=10000),0.841,0.835,-0.001,0.811,-0.002,0.835,0,0,469,0.798,469,0.798,0:00:14.211103,0:00:00
,,,,,,,,,,,,,,,,,,
64,5,1,0.85,LogisticRegression(max_iter=10000),0.838,0.834,-0.002,0.809,-0.004,0.834,0,0,426,0.724,426,0.724,0:00:09.752898,0:00:00
,,,,,,,,,,,,,,,,,,
64,5,1,0.8,LogisticRegression(max_iter=10000),0.835,0.832,-0.004,0.808,-0.005,0.832,0,0,379,0.645,379,0.645,0:00:12.385080,0:00:00
,,,,,,,,,,,,,,,,,,
64,5,1,0.75,LogisticRegression(max_iter=10000),0.834,0.832,-0.004,0.808,-0.005,0.832,0,0,340,0.578,340,0.578,0:00:13.312875,0:00:00
,,,,,,,,,,,,,,,,,,
64,5,1,0.7,LogisticRegression(max_iter=10000),0.831,0.834,-0.002,0.811,-0.002,0.834,0,0,291,0.495,291,0.495,0:00:05.988643,0:00:00
,,,,,,,,,,,,,,,,,,
64,5,1,0.65,LogisticRegression(max_iter=10000),0.83,0.834,-0.002,0.81,-0.003,0.834,0,0,238,0.405,238,0.405,0:00:04.791482,0:00:00
,,,,,,,,,,,,,,,,,,
64,5,1,0.6,LogisticRegression(max_iter=10000),0.831,0.832,-0.004,0.808,-0.006,0.832,0,0,182,0.31,182,0.31,0:00:03.363820,0:00:00
,,,,,,,,,,,,,,,,,,
64,10,1,1,LogisticRegression(max_iter=10000),0.854,0.827,0,0.802,0,0.827,0,0,1422,1,1422,1,0:01:06.214428,0:00:00
,,,,,,,,,,,,,,,,,,
64,10,1,0.95,LogisticRegression(max_iter=10000),0.854,0.826,-0.001,0.801,-0.001,0.826,0,0,1312,0.923,1312,0.923,0:00:50.033256,0:00:00
,,,,,,,,,,,,,,,,,,
64,10,1,0.9,LogisticRegression(max_iter=10000),0.853,0.826,-0.001,0.801,-0.001,0.826,0,0,1252,0.88,1252,0.88,0:00:54.609385,0:00:00
,,,,,,,,,,,,,,,,,,
64,10,1,0.85,LogisticRegression(max_iter=10000),0.853,0.826,0,0.802,0,0.826,0,0,1182,0.831,1182,0.831,0:00:44.021977,0:00:00
,,,,,,,,,,,,,,,,,,
64,10,1,0.8,LogisticRegression(max_iter=10000),0.851,0.828,0.001,0.804,0.002,0.828,0,0,1126,0.792,1126,0.792,0:00:44.175412,0:00:00
,,,,,,,,,,,,,,,,,,
64,10,1,0.75,LogisticRegression(max_iter=10000),0.851,0.828,0.001,0.804,0.002,0.828,0,0,1062,0.747,1062,0.747,0:00:43.231839,0:00:00
,,,,,,,,,,,,,,,,,,
64,10,1,0.7,LogisticRegression(max_iter=10000),0.85,0.832,0.005,0.808,0.006,0.832,0,0,994,0.699,994,0.699,0:00:45.719992,0:00:00
,,,,,,,,,,,,,,,,,,
64,10,1,0.65,LogisticRegression(max_iter=10000),0.85,0.834,0.007,0.81,0.008,0.834,0,0,850,0.598,850,0.598,0:00:26.083164,0:00:00
,,,,,,,,,,,,,,,,,,
64,10,1,0.6,LogisticRegression(max_iter=10000),0.849,0.839,0.013,0.817,0.015,0.839,0,0,777,0.546,777,0.546,0:00:27.188224,0:00:00
,,,,,,,,,,,,,,,,,,
64,15,1,1,LogisticRegression(max_iter=10000),0.855,0.825,0,0.8,0,0.825,0,0,1534,1,1534,1,0:01:13.804847,0:00:00
,,,,,,,,,,,,,,,,,,
64,15,1,0.95,LogisticRegression(max_iter=10000),0.855,0.828,0.002,0.803,0.003,0.828,0,0,1446,0.943,1446,0.943,0:02:09.502148,0:00:00
,,,,,,,,,,,,,,,,,,
64,15,1,0.9,LogisticRegression(max_iter=10000),0.855,0.828,0.003,0.803,0.003,0.828,0,0,1393,0.908,1393,0.908,0:02:43.595320,0:00:00
,,,,,,,,,,,,,,,,,,
64,15,1,0.85,LogisticRegression(max_iter=10000),0.855,0.828,0.003,0.804,0.004,0.828,0,0,1335,0.87,1335,0.87,0:02:28.858201,0:00:00
,,,,,,,,,,,,,,,,,,
64,15,1,0.8,LogisticRegression(max_iter=10000),0.854,0.828,0.003,0.804,0.004,0.828,0,0,1301,0.848,1301,0.848,0:03:00.728773,0:00:00
,,,,,,,,,,,,,,,,,,
64,15,1,0.75,LogisticRegression(max_iter=10000),0.854,0.829,0.003,0.804,0.004,0.829,0,0,1260,0.821,1260,0.821,0:03:10.351641,0:00:00
,,,,,,,,,,,,,,,,,,
64,15,1,0.7,LogisticRegression(max_iter=10000),0.854,0.828,0.003,0.804,0.004,0.828,0,0,1196,0.78,1196,0.78,0:02:16.159722,0:00:00
,,,,,,,,,,,,,,,,,,
64,15,1,0.65,LogisticRegression(max_iter=10000),0.851,0.829,0.004,0.805,0.005,0.829,0,0,1083,0.706,1083,0.706,0:02:12.483199,0:00:00
,,,,,,,,,,,,,,,,,,
64,15,1,0.6,LogisticRegression(max_iter=10000),0.851,0.831,0.006,0.807,0.007,0.831,0,0,1042,0.679,1042,0.679,0:01:41.112440,0:00:00
16,5,1,0.55,LogisticRegression(max_iter=10000),0.816,0.808,-0.192,0.773,-0.227,0.808,0,-1.0,31,31.0,31,31.0,0:00:00.186697,0:00:00,

16,10,1,0.55,LogisticRegression(max_iter=10000),0.838,0.843,-0.157,0.819,-0.181,0.843,0,-1.0,244,244.0,244,244.0,0:00:03.669796,0:00:00,

16,15,1,0.55,LogisticRegression(max_iter=10000),0.847,0.843,-0.157,0.82,-0.18,0.843,0,-1.0,495,495.0,495,495.0,0:00:14.490982,0:00:00,

32,5,1,0.55,LogisticRegression(max_iter=10000),0.818,0.815,-0.185,0.787,-0.213,0.815,0,-1.0,63,63.0,63,63.0,0:00:00.535956,0:00:00,

32,10,1,0.55,LogisticRegression(max_iter=10000),0.84,0.835,-0.165,0.811,-0.189,0.835,0,-1.0,395,395.0,395,395.0,0:00:11.751326,0:00:00,

32,15,1,0.55,LogisticRegression(max_iter=10000),0.845,0.833,-0.167,0.809,-0.191,0.833,0,-1.0,701,701.0,701,701.0,0:00:22.071256,0:00:00,

64,5,1,0.55,LogisticRegression(max_iter=10000),0.825,0.834,-0.166,0.809,-0.191,0.834,0,-1.0,104,104.0,104,104.0,0:00:01.890297,0:00:00,

64,10,1,0.55,LogisticRegression(max_iter=10000),0.844,0.839,-0.161,0.816,-0.184,0.839,0,-1.0,588,588.0,588,588.0,0:00:17.205827,0:00:00,

64,15,1,0.55,LogisticRegression(max_iter=10000),0.85,0.831,-0.169,0.807,-0.193,0.831,0,-1.0,913,913.0,913,913.0,0:00:28.953736,0:00:00,

Forest Size, Forest Depth, Patterns threshold, Edges Threshold, Learner, Train Accuracy, Test Accuracy, Test Accuracy (gain), F1_macro, F1_macro (gain), F1_micro, ROC_AUC, ROC_AUC (gain), Patterns Count, Patterns Ratio, Nodes Count, Nodes Ratio, Training Time, Pruning Time

Forest Size, Forest Depth, Patterns threshold, Edges Threshold, Learner, Train Accuracy, Test Accuracy, Test Accuracy (gain), F1_macro, F1_macro (gain), F1_micro, ROC_AUC, ROC_AUC (gain), Patterns Count, Patterns Ratio, Nodes Count, Nodes Ratio, Training Time, Pruning Time

64,15,1,0.995,LogisticRegression(max_iter=10000),0.836,0.84,-0.16,0.816,-0.184,0.84,0,-1.0,250,250.0,250,250.0,0:00:06.716253,0:00:00,0:00:00.002552,

