Forest Size, Forest Depth, Patterns threshold, Edges Threshold, Learner, Train Accuracy, Test Accuracy, Test Accuracy (gain), F1_macro, F1_macro (gain), F1_micro, ROC_AUC, ROC_AUC (gain), Patterns Count, Patterns Ratio, Nodes Count, Nodes Ratio, Training Time, Pruning Time

16,5,1,1.0,LogisticRegression(max_iter=10000),0.998,0.997,0.0,0.991,0.0,0.997,0,0,155,155.0,155,155.0,0:00:03.591178,0:00:00,

16,5,1,0.95,LogisticRegression(max_iter=10000),0.998,0.997,0.0,0.991,0.0,0.997,0,0,139,139.0,139,139.0,0:00:03.040910,0:00:00,

16,5,1,0.9,LogisticRegression(max_iter=10000),0.998,0.997,0.0,0.991,0.0,0.997,0,0,122,122.0,122,122.0,0:00:02.573006,0:00:00,

16,5,1,0.85,LogisticRegression(max_iter=10000),0.997,0.997,-0.001,0.99,-0.002,0.997,0,0,107,107.0,107,107.0,0:00:02.178033,0:00:00,

16,5,1,0.8,LogisticRegression(max_iter=10000),0.997,0.996,-0.001,0.989,-0.003,0.996,0,0,99,99.0,99,99.0,0:00:02.057568,0:00:00,

16,5,1,0.75,LogisticRegression(max_iter=10000),0.997,0.996,-0.001,0.988,-0.003,0.996,0,0,84,84.0,84,84.0,0:00:01.972637,0:00:00,

16,5,1,0.7,LogisticRegression(max_iter=10000),0.997,0.996,-0.002,0.986,-0.005,0.996,0,0,73,73.0,73,73.0,0:00:01.600977,0:00:00,

16,5,1,0.65,LogisticRegression(max_iter=10000),0.997,0.996,-0.001,0.987,-0.004,0.996,0,0,59,59.0,59,59.0,0:00:01.513321,0:00:00,

16,5,1,0.6,LogisticRegression(max_iter=10000),0.996,0.997,-0.001,0.989,-0.002,0.997,0,0,43,43.0,43,43.0,0:00:01.037834,0:00:00,

16,10,1,1.0,LogisticRegression(max_iter=10000),0.999,0.998,0.0,0.995,0.0,0.998,0,0,280,280.0,280,280.0,0:00:05.811828,0:00:00,

16,10,1,0.95,LogisticRegression(max_iter=10000),0.999,0.998,-0.001,0.993,-0.002,0.998,0,0,247,247.0,247,247.0,0:00:06.084073,0:00:00,

16,10,1,0.9,LogisticRegression(max_iter=10000),0.999,0.998,-0.001,0.993,-0.002,0.998,0,0,223,223.0,223,223.0,0:00:06.572467,0:00:00,

16,10,1,0.85,LogisticRegression(max_iter=10000),0.998,0.997,-0.002,0.99,-0.005,0.997,0,0,196,196.0,196,196.0,0:00:07.827143,0:00:00,

16,10,1,0.8,LogisticRegression(max_iter=10000),0.998,0.997,-0.002,0.99,-0.005,0.997,0,0,177,177.0,177,177.0,0:00:05.572088,0:00:00,

16,10,1,0.75,LogisticRegression(max_iter=10000),0.998,0.998,-0.001,0.993,-0.002,0.998,0,0,155,155.0,155,155.0,0:00:03.776700,0:00:00,

16,10,1,0.7,LogisticRegression(max_iter=10000),0.998,0.997,-0.001,0.991,-0.003,0.997,0,0,123,123.0,123,123.0,0:00:03.689854,0:00:00,

16,10,1,0.65,LogisticRegression(max_iter=10000),0.998,0.996,-0.002,0.989,-0.006,0.996,0,0,94,94.0,94,94.0,0:00:02.031793,0:00:00,

16,10,1,0.6,LogisticRegression(max_iter=10000),0.997,0.996,-0.002,0.989,-0.006,0.996,0,0,73,73.0,73,73.0,0:00:01.645593,0:00:00,

16,15,1,1.0,LogisticRegression(max_iter=10000),0.999,0.999,0.0,0.997,0.0,0.999,0,0,290,290.0,290,290.0,0:00:06.105151,0:00:00,

16,15,1,0.95,LogisticRegression(max_iter=10000),0.999,0.998,-0.001,0.995,-0.002,0.998,0,0,257,257.0,257,257.0,0:00:04.948306,0:00:00,

16,15,1,0.9,LogisticRegression(max_iter=10000),0.999,0.998,-0.001,0.995,-0.002,0.998,0,0,227,227.0,227,227.0,0:00:03.594500,0:00:00,

16,15,1,0.85,LogisticRegression(max_iter=10000),0.999,0.998,-0.001,0.995,-0.002,0.998,0,0,207,207.0,207,207.0,0:00:06.068345,0:00:00,

16,15,1,0.8,LogisticRegression(max_iter=10000),0.999,0.998,-0.001,0.995,-0.002,0.998,0,0,187,187.0,187,187.0,0:00:04.426364,0:00:00,

16,15,1,0.75,LogisticRegression(max_iter=10000),0.999,0.999,0.0,0.997,0.0,0.999,0,0,164,164.0,164,164.0,0:00:07.835156,0:00:00,

16,15,1,0.7,LogisticRegression(max_iter=10000),0.998,0.998,-0.001,0.995,-0.002,0.998,0,0,139,139.0,139,139.0,0:00:05.297122,0:00:00,

16,15,1,0.65,LogisticRegression(max_iter=10000),0.998,0.997,-0.002,0.991,-0.005,0.997,0,0,95,95.0,95,95.0,0:00:03.405504,0:00:00,

16,15,1,0.6,LogisticRegression(max_iter=10000),0.997,0.997,-0.002,0.991,-0.005,0.997,0,0,72,72.0,72,72.0,0:00:02.564380,0:00:00,

32,5,1,1.0,LogisticRegression(max_iter=10000),0.998,0.998,0.0,0.995,0.0,0.998,0,0,241,241.0,241,241.0,0:00:10.534264,0:00:00,

32,5,1,0.95,LogisticRegression(max_iter=10000),0.998,0.997,-0.001,0.991,-0.003,0.997,0,0,217,217.0,217,217.0,0:00:04.134395,0:00:00,

32,5,1,0.9,LogisticRegression(max_iter=10000),0.998,0.998,-0.001,0.993,-0.002,0.998,0,0,184,184.0,184,184.0,0:00:03.186207,0:00:00,

32,5,1,0.85,LogisticRegression(max_iter=10000),0.998,0.998,-0.001,0.993,-0.002,0.998,0,0,165,165.0,165,165.0,0:00:02.924290,0:00:00,

32,5,1,0.8,LogisticRegression(max_iter=10000),0.997,0.997,-0.001,0.991,-0.003,0.997,0,0,139,139.0,139,139.0,0:00:02.846025,0:00:00,

32,5,1,0.75,LogisticRegression(max_iter=10000),0.997,0.997,-0.001,0.991,-0.003,0.997,0,0,123,123.0,123,123.0,0:00:02.623374,0:00:00,

32,5,1,0.7,LogisticRegression(max_iter=10000),0.997,0.996,-0.002,0.989,-0.006,0.996,0,0,102,102.0,102,102.0,0:00:02.149809,0:00:00,

32,5,1,0.65,LogisticRegression(max_iter=10000),0.997,0.996,-0.002,0.989,-0.006,0.996,0,0,83,83.0,83,83.0,0:00:01.713385,0:00:00,

32,5,1,0.6,LogisticRegression(max_iter=10000),0.996,0.996,-0.002,0.988,-0.007,0.996,0,0,60,60.0,60,60.0,0:00:01.662506,0:00:00,

32,10,1,1.0,LogisticRegression(max_iter=10000),1.0,0.998,0.0,0.993,0.0,0.998,0,0,384,384.0,384,384.0,0:00:08.275712,0:00:00,

32,10,1,0.95,LogisticRegression(max_iter=10000),1.0,0.998,0.0,0.993,0.0,0.998,0,0,351,351.0,351,351.0,0:00:06.970374,0:00:00,

32,10,1,0.9,LogisticRegression(max_iter=10000),0.999,0.998,0.001,0.995,0.002,0.998,0,0,313,313.0,313,313.0,0:00:08.271357,0:00:00,

32,10,1,0.85,LogisticRegression(max_iter=10000),0.999,0.999,0.001,0.997,0.003,0.999,0,0,288,288.0,288,288.0,0:00:05.461248,0:00:00,

32,10,1,0.8,LogisticRegression(max_iter=10000),0.999,0.999,0.001,0.997,0.003,0.999,0,0,266,266.0,266,266.0,0:00:05.022964,0:00:00,

32,10,1,0.75,LogisticRegression(max_iter=10000),0.999,0.998,0.001,0.995,0.002,0.998,0,0,243,243.0,243,243.0,0:00:05.883868,0:00:00,

32,10,1,0.7,LogisticRegression(max_iter=10000),0.999,0.999,0.001,0.997,0.003,0.999,0,0,208,208.0,208,208.0,0:00:04.889400,0:00:00,

32,10,1,0.65,LogisticRegression(max_iter=10000),0.999,0.998,0.001,0.995,0.002,0.998,0,0,170,170.0,170,170.0,0:00:04.489982,0:00:00,

32,10,1,0.6,LogisticRegression(max_iter=10000),0.999,0.997,-0.001,0.991,-0.002,0.997,0,0,134,134.0,134,134.0,0:00:02.970070,0:00:00,

32,15,1,1.0,LogisticRegression(max_iter=10000),1.0,0.998,0.0,0.993,0.0,0.998,0,0,406,406.0,406,406.0,0:00:08.366646,0:00:00,

32,15,1,0.95,LogisticRegression(max_iter=10000),1.0,0.998,0.001,0.995,0.002,0.998,0,0,367,367.0,367,367.0,0:00:07.032247,0:00:00,

32,15,1,0.9,LogisticRegression(max_iter=10000),1.0,0.998,0.0,0.993,0.0,0.998,0,0,325,325.0,325,325.0,0:00:06.262262,0:00:00,

32,15,1,0.85,LogisticRegression(max_iter=10000),0.999,0.998,0.0,0.993,0.0,0.998,0,0,289,289.0,289,289.0,0:00:05.416932,0:00:00,

32,15,1,0.8,LogisticRegression(max_iter=10000),0.999,0.997,-0.001,0.991,-0.002,0.997,0,0,263,263.0,263,263.0,0:00:06.474939,0:00:00,

32,15,1,0.75,LogisticRegression(max_iter=10000),0.999,0.997,-0.001,0.991,-0.002,0.997,0,0,234,234.0,234,234.0,0:00:04.362852,0:00:00,

32,15,1,0.7,LogisticRegression(max_iter=10000),0.999,0.997,-0.001,0.991,-0.002,0.997,0,0,203,203.0,203,203.0,0:00:03.544207,0:00:00,

32,15,1,0.65,LogisticRegression(max_iter=10000),0.998,0.997,-0.001,0.991,-0.002,0.997,0,0,163,163.0,163,163.0,0:00:02.757901,0:00:00,

32,15,1,0.6,LogisticRegression(max_iter=10000),0.998,0.997,-0.001,0.99,-0.003,0.997,0,0,133,133.0,133,133.0,0:00:02.927266,0:00:00,

64,5,1,1.0,LogisticRegression(max_iter=10000),0.999,0.999,0.0,0.997,0.0,0.999,0,0,327,327.0,327,327.0,0:00:06.113786,0:00:00,

64,5,1,0.95,LogisticRegression(max_iter=10000),0.999,0.999,0.0,0.997,0.0,0.999,0,0,292,292.0,292,292.0,0:00:07.536890,0:00:00,

64,5,1,0.9,LogisticRegression(max_iter=10000),0.998,0.998,-0.001,0.993,-0.003,0.998,0,0,262,262.0,262,262.0,0:00:06.664196,0:00:00,

64,5,1,0.85,LogisticRegression(max_iter=10000),0.999,0.997,-0.002,0.991,-0.005,0.997,0,0,235,235.0,235,235.0,0:00:06.348459,0:00:00,

64,5,1,0.8,LogisticRegression(max_iter=10000),0.998,0.997,-0.002,0.991,-0.005,0.997,0,0,208,208.0,208,208.0,0:00:04.424124,0:00:00,

64,5,1,0.75,LogisticRegression(max_iter=10000),0.998,0.997,-0.002,0.991,-0.005,0.997,0,0,188,188.0,188,188.0,0:00:03.458242,0:00:00,

64,5,1,0.7,LogisticRegression(max_iter=10000),0.997,0.997,-0.002,0.991,-0.005,0.997,0,0,157,157.0,157,157.0,0:00:03.440321,0:00:00,

64,5,1,0.65,LogisticRegression(max_iter=10000),0.997,0.997,-0.002,0.991,-0.005,0.997,0,0,133,133.0,133,133.0,0:00:03.333512,0:00:00,

64,5,1,0.6,LogisticRegression(max_iter=10000),0.997,0.997,-0.002,0.991,-0.005,0.997,0,0,105,105.0,105,105.0,0:00:02.301761,0:00:00,

64,10,1,1.0,LogisticRegression(max_iter=10000),1.0,0.998,0.0,0.993,0.0,0.998,0,0,542,542.0,542,542.0,0:00:11.212616,0:00:00,

64,10,1,0.95,LogisticRegression(max_iter=10000),1.0,0.998,0.0,0.993,0.0,0.998,0,0,483,483.0,483,483.0,0:00:13.495248,0:00:00,

64,10,1,0.9,LogisticRegression(max_iter=10000),1.0,0.998,0.0,0.993,0.0,0.998,0,0,454,454.0,454,454.0,0:00:12.244243,0:00:00,

64,10,1,0.85,LogisticRegression(max_iter=10000),1.0,0.998,0.0,0.993,0.0,0.998,0,0,405,405.0,405,405.0,0:00:16.907748,0:00:00,

64,10,1,0.8,LogisticRegression(max_iter=10000),1.0,0.998,0.0,0.993,0.0,0.998,0,0,372,372.0,372,372.0,0:00:07.763093,0:00:00,

64,10,1,0.75,LogisticRegression(max_iter=10000),1.0,0.998,0.0,0.993,0.0,0.998,0,0,346,346.0,346,346.0,0:00:11.321412,0:00:00,

64,10,1,0.7,LogisticRegression(max_iter=10000),0.999,0.998,0.001,0.995,0.002,0.998,0,0,308,308.0,308,308.0,0:00:08.883350,0:00:00,

64,10,1,0.65,LogisticRegression(max_iter=10000),0.999,0.998,0.0,0.993,-0.0,0.998,0,0,248,248.0,248,248.0,0:00:06.809598,0:00:00,

64,10,1,0.6,LogisticRegression(max_iter=10000),0.999,0.998,0.0,0.993,-0.0,0.998,0,0,207,207.0,207,207.0,0:00:05.172645,0:00:00,

64,15,1,1.0,LogisticRegression(max_iter=10000),1.0,0.998,0.0,0.993,0.0,0.998,0,0,544,544.0,544,544.0,0:00:12.779398,0:00:00,

64,15,1,0.95,LogisticRegression(max_iter=10000),1.0,0.998,0.0,0.993,0.0,0.998,0,0,503,503.0,503,503.0,0:00:11.707416,0:00:00,

64,15,1,0.9,LogisticRegression(max_iter=10000),1.0,0.998,0.0,0.993,0.0,0.998,0,0,483,483.0,483,483.0,0:00:13.893057,0:00:00,

64,15,1,0.85,LogisticRegression(max_iter=10000),1.0,0.998,0.0,0.993,0.0,0.998,0,0,448,448.0,448,448.0,0:00:16.221104,0:00:00,

64,15,1,0.8,LogisticRegression(max_iter=10000),1.0,0.998,0.0,0.993,0.0,0.998,0,0,416,416.0,416,416.0,0:00:25.042354,0:00:00,

64,15,1,0.75,LogisticRegression(max_iter=10000),1.0,0.998,0.0,0.993,0.0,0.998,0,0,380,380.0,380,380.0,0:00:24.871294,0:00:00,

64,15,1,0.7,LogisticRegression(max_iter=10000),0.999,0.998,0.0,0.993,0.0,0.998,0,0,334,334.0,334,334.0,0:00:30.110737,0:00:00,

64,15,1,0.65,LogisticRegression(max_iter=10000),0.999,0.998,0.001,0.995,0.002,0.998,0,0,253,253.0,253,253.0,0:00:25.030401,0:00:00,

64,15,1,0.6,LogisticRegression(max_iter=10000),0.999,0.999,0.001,0.997,0.003,0.999,0,0,215,215.0,215,215.0,0:00:21.486983,0:00:00,

16,5,1,0.55,LogisticRegression(max_iter=10000),0.987,0.986,-0.014,0.952,-0.048,0.986,0,-1.0,20,20.0,20,20.0,0:00:00.517334,0:00:00,

16,10,1,0.55,LogisticRegression(max_iter=10000),0.997,0.996,-0.004,0.989,-0.011,0.996,0,-1.0,53,53.0,53,53.0,0:00:00.950605,0:00:00,

16,15,1,0.55,LogisticRegression(max_iter=10000),0.997,0.997,-0.003,0.99,-0.01,0.997,0,-1.0,55,55.0,55,55.0,0:00:00.995493,0:00:00,

32,5,1,0.55,LogisticRegression(max_iter=10000),0.991,0.991,-0.009,0.977,-0.023,0.991,0,-1.0,35,35.0,35,35.0,0:00:00.604448,0:00:00,

32,10,1,0.55,LogisticRegression(max_iter=10000),0.998,0.997,-0.003,0.99,-0.01,0.997,0,-1.0,86,86.0,86,86.0,0:00:02.067821,0:00:00,

32,15,1,0.55,LogisticRegression(max_iter=10000),0.997,0.996,-0.004,0.989,-0.011,0.996,0,-1.0,89,89.0,89,89.0,0:00:02.608006,0:00:00,

64,5,1,0.55,LogisticRegression(max_iter=10000),0.997,0.997,-0.003,0.99,-0.01,0.997,0,-1.0,64,64.0,64,64.0,0:00:02.258733,0:00:00,

64,10,1,0.55,LogisticRegression(max_iter=10000),0.999,0.997,-0.003,0.991,-0.009,0.997,0,-1.0,155,155.0,155,155.0,0:00:04.347748,0:00:00,

64,15,1,0.55,LogisticRegression(max_iter=10000),0.999,0.998,-0.002,0.993,-0.007,0.998,0,-1.0,169,169.0,169,169.0,0:00:03.355041,0:00:00,

