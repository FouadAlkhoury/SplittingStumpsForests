64,5,1,1.0,LogisticRegression(max_iter=10000),0.843,0.837,0.0,0.837,0.0,0.837,0.837,0.0,319,1.0,319,1.0,0:00:08.757596,0:00:00,

64,5,1,0.95,LogisticRegression(max_iter=10000),0.833,0.831,-0.007,0.83,-0.007,0.831,0.831,-0.007,141,0.442,141,0.442,0:00:02.854802,0:00:00,

64,5,1,0.9,LogisticRegression(max_iter=10000),0.827,0.826,-0.011,0.826,-0.011,0.826,0.826,-0.011,85,0.266,85,0.266,0:00:00.993611,0:00:00,

64,5,1,0.85,LogisticRegression(max_iter=10000),0.824,0.824,-0.013,0.824,-0.013,0.824,0.824,-0.013,53,0.166,53,0.166,0:00:00.660821,0:00:00,

64,5,1,0.8,LogisticRegression(max_iter=10000),0.797,0.801,-0.036,0.801,-0.036,0.801,0.803,-0.035,28,0.088,28,0.088,0:00:00.184822,0:00:00,

64,5,1,0.75,LogisticRegression(max_iter=10000),0.793,0.796,-0.041,0.796,-0.041,0.796,0.798,-0.039,18,0.056,18,0.056,0:00:00.174834,0:00:00,

64,5,1,0.7,LogisticRegression(max_iter=10000),0.784,0.792,-0.045,0.792,-0.045,0.792,0.792,-0.046,11,0.034,11,0.034,0:00:00.143940,0:00:00,

64,5,1,0.65,LogisticRegression(max_iter=10000),0.772,0.784,-0.054,0.783,-0.054,0.784,0.783,-0.055,8,0.025,8,0.025,0:00:00.063772,0:00:00,

64,5,1,0.6,LogisticRegression(max_iter=10000),0.754,0.76,-0.077,0.759,-0.078,0.76,0.764,-0.073,3,0.009,3,0.009,0:00:00.016575,0:00:00,

64,10,1,1.0,LogisticRegression(max_iter=10000),0.864,0.834,0.0,0.834,0.0,0.834,0.834,0.0,2075,1.0,2075,1.0,0:02:02.190606,0:00:00,

64,10,1,0.95,LogisticRegression(max_iter=10000),0.847,0.831,-0.002,0.831,-0.002,0.831,0.831,-0.002,626,0.302,626,0.302,0:00:24.523170,0:00:00,

64,10,1,0.9,LogisticRegression(max_iter=10000),0.835,0.83,-0.004,0.829,-0.004,0.83,0.83,-0.004,192,0.093,192,0.093,0:00:05.748891,0:00:00,

64,10,1,0.85,LogisticRegression(max_iter=10000),0.829,0.829,-0.005,0.828,-0.005,0.829,0.829,-0.005,87,0.042,87,0.042,0:00:01.851395,0:00:00,

64,10,1,0.8,LogisticRegression(max_iter=10000),0.805,0.808,-0.026,0.808,-0.025,0.808,0.809,-0.024,31,0.015,31,0.015,0:00:00.229667,0:00:00,

64,10,1,0.75,LogisticRegression(max_iter=10000),0.795,0.801,-0.033,0.801,-0.033,0.801,0.803,-0.031,19,0.009,19,0.009,0:00:00.093661,0:00:00,

64,10,1,0.7,LogisticRegression(max_iter=10000),0.78,0.784,-0.05,0.784,-0.05,0.784,0.787,-0.047,9,0.004,9,0.004,0:00:00.033756,0:00:00,

64,10,1,0.65,LogisticRegression(max_iter=10000),0.748,0.756,-0.077,0.753,-0.08,0.756,0.753,-0.081,4,0.002,4,0.002,0:00:00.015207,0:00:00,

64,10,1,0.6,LogisticRegression(max_iter=10000),0.754,0.76,-0.073,0.759,-0.074,0.76,0.764,-0.07,3,0.001,3,0.001,0:00:00.015990,0:00:00,

64,15,1,1.0,LogisticRegression(max_iter=10000),0.893,0.823,0.0,0.822,0.0,0.823,0.823,0.0,7073,1.0,7073,1.0,0:13:24.961464,0:00:00,

64,15,1,0.95,LogisticRegression(max_iter=10000),0.859,0.831,0.009,0.831,0.009,0.831,0.831,0.009,1346,0.19,1346,0.19,0:01:24.724773,0:00:00,

64,15,1,0.9,LogisticRegression(max_iter=10000),0.841,0.833,0.01,0.833,0.01,0.833,0.833,0.01,350,0.049,350,0.049,0:00:09.258311,0:00:00,

64,15,1,0.85,LogisticRegression(max_iter=10000),0.827,0.826,0.004,0.826,0.004,0.826,0.827,0.004,94,0.013,94,0.013,0:00:01.412957,0:00:00,

64,15,1,0.8,LogisticRegression(max_iter=10000),0.815,0.818,-0.004,0.818,-0.004,0.818,0.818,-0.004,51,0.007,51,0.007,0:00:01.008816,0:00:00,

64,15,1,0.75,LogisticRegression(max_iter=10000),0.795,0.804,-0.019,0.804,-0.019,0.804,0.805,-0.017,25,0.004,25,0.004,0:00:00.382930,0:00:00,

64,15,1,0.7,LogisticRegression(max_iter=10000),0.794,0.799,-0.024,0.799,-0.024,0.799,0.801,-0.021,16,0.002,16,0.002,0:00:00.292524,0:00:00,

64,15,1,0.65,LogisticRegression(max_iter=10000),0.777,0.784,-0.039,0.783,-0.039,0.784,0.783,-0.04,11,0.002,11,0.002,0:00:00.197307,0:00:00,

64,15,1,0.6,LogisticRegression(max_iter=10000),0.754,0.76,-0.062,0.759,-0.063,0.76,0.764,-0.059,3,0.0,3,0.0,0:00:00.029502,0:00:00,

Forest Size, Forest Depth, Patterns threshold, Edges Threshold, Learner, Train Accuracy, Test Accuracy, Test Accuracy (gain), F1_macro, F1_macro (gain), F1_micro, ROC_AUC, ROC_AUC (gain), Patterns Count, Patterns Ratio, Nodes Count, Nodes Ratio, Training Time, Pruning Time

4,5,1,0.95,LogisticRegression(max_iter=10000),0.812,0.811,-0.189,0.811,-0.189,0.811,0,-1.0,33,33.0,33,33.0,0:00:00.645125,0:00:00,

4,5,1,0.9,LogisticRegression(max_iter=10000),0.795,0.793,-0.207,0.793,-0.207,0.793,0,-1.0,14,14.0,14,14.0,0:00:00.095157,0:00:00,

4,5,1,0.85,LogisticRegression(max_iter=10000),0.791,0.792,-0.208,0.792,-0.208,0.792,0,-1.0,13,13.0,13,13.0,0:00:00.138148,0:00:00,

4,5,1,0.8,LogisticRegression(max_iter=10000),0.78,0.781,-0.219,0.781,-0.219,0.781,0,-1.0,8,8.0,8,8.0,0:00:00.026849,0:00:00,

4,5,1,0.75,LogisticRegression(max_iter=10000),0.757,0.763,-0.237,0.763,-0.237,0.763,0,-1.0,3,3.0,3,3.0,0:00:00.019820,0:00:00,

4,5,1,0.7,LogisticRegression(max_iter=10000),0.757,0.763,-0.237,0.763,-0.237,0.763,0,-1.0,3,3.0,3,3.0,0:00:00.022991,0:00:00,

4,10,1,0.95,LogisticRegression(max_iter=10000),0.833,0.831,-0.169,0.83,-0.17,0.831,0,-1.0,161,161.0,161,161.0,0:00:05.497909,0:00:00,

4,10,1,0.9,LogisticRegression(max_iter=10000),0.829,0.825,-0.175,0.825,-0.175,0.825,0,-1.0,81,81.0,81,81.0,0:00:01.805029,0:00:00,

4,10,1,0.85,LogisticRegression(max_iter=10000),0.822,0.824,-0.176,0.824,-0.176,0.824,0,-1.0,31,31.0,31,31.0,0:00:00.737010,0:00:00,

4,10,1,0.8,LogisticRegression(max_iter=10000),0.799,0.802,-0.198,0.802,-0.198,0.802,0,-1.0,17,17.0,17,17.0,0:00:00.118805,0:00:00,

4,10,1,0.75,LogisticRegression(max_iter=10000),0.759,0.768,-0.232,0.766,-0.234,0.768,0,-1.0,3,3.0,3,3.0,0:00:00.023210,0:00:00,

4,10,1,0.7,LogisticRegression(max_iter=10000),0.759,0.768,-0.232,0.766,-0.234,0.768,0,-1.0,3,3.0,3,3.0,0:00:00.021900,0:00:00,

4,15,1,0.95,LogisticRegression(max_iter=10000),0.837,0.833,-0.167,0.833,-0.167,0.833,0,-1.0,231,231.0,231,231.0,0:00:09.043321,0:00:00,

4,15,1,0.9,LogisticRegression(max_iter=10000),0.824,0.824,-0.176,0.824,-0.176,0.824,0,-1.0,61,61.0,61,61.0,0:00:00.700743,0:00:00,

4,15,1,0.85,LogisticRegression(max_iter=10000),0.78,0.784,-0.216,0.784,-0.216,0.784,0,-1.0,15,15.0,15,15.0,0:00:00.083818,0:00:00,

4,15,1,0.8,LogisticRegression(max_iter=10000),0.76,0.766,-0.234,0.766,-0.234,0.766,0,-1.0,11,11.0,11,11.0,0:00:00.064671,0:00:00,

4,15,1,0.75,LogisticRegression(max_iter=10000),0.754,0.76,-0.24,0.759,-0.241,0.76,0,-1.0,3,3.0,3,3.0,0:00:00.071638,0:00:00,

4,15,1,0.7,LogisticRegression(max_iter=10000),0.754,0.76,-0.24,0.759,-0.241,0.76,0,-1.0,1,1.0,1,1.0,0:00:00.133943,0:00:00,

8,5,1,0.95,LogisticRegression(max_iter=10000),0.825,0.823,-0.177,0.823,-0.177,0.823,0,-1.0,54,54.0,54,54.0,0:00:01.234915,0:00:00,

8,5,1,0.9,LogisticRegression(max_iter=10000),0.815,0.817,-0.183,0.817,-0.183,0.817,0,-1.0,30,30.0,30,30.0,0:00:00.194546,0:00:00,

8,5,1,0.85,LogisticRegression(max_iter=10000),0.812,0.815,-0.185,0.815,-0.185,0.815,0,-1.0,26,26.0,26,26.0,0:00:00.476833,0:00:00,

8,5,1,0.8,LogisticRegression(max_iter=10000),0.793,0.801,-0.199,0.801,-0.199,0.801,0,-1.0,13,13.0,13,13.0,0:00:00.075337,0:00:00,

8,5,1,0.75,LogisticRegression(max_iter=10000),0.777,0.783,-0.217,0.783,-0.217,0.783,0,-1.0,5,5.0,5,5.0,0:00:00.025345,0:00:00,

8,5,1,0.7,LogisticRegression(max_iter=10000),0.765,0.775,-0.225,0.774,-0.226,0.775,0,-1.0,4,4.0,4,4.0,0:00:00.037273,0:00:00,

8,10,1,0.95,LogisticRegression(max_iter=10000),0.84,0.834,-0.166,0.834,-0.166,0.834,0,-1.0,205,205.0,205,205.0,0:00:06.883213,0:00:00,

8,10,1,0.9,LogisticRegression(max_iter=10000),0.827,0.829,-0.171,0.829,-0.171,0.829,0,-1.0,81,81.0,81,81.0,0:00:01.793716,0:00:00,

8,10,1,0.85,LogisticRegression(max_iter=10000),0.803,0.807,-0.193,0.807,-0.193,0.807,0,-1.0,38,38.0,38,38.0,0:00:00.576552,0:00:00,

8,10,1,0.8,LogisticRegression(max_iter=10000),0.766,0.773,-0.227,0.773,-0.227,0.773,0,-1.0,12,12.0,12,12.0,0:00:00.184330,0:00:00,

8,10,1,0.75,LogisticRegression(max_iter=10000),0.766,0.773,-0.227,0.773,-0.227,0.773,0,-1.0,10,10.0,10,10.0,0:00:00.265978,0:00:00,

8,10,1,0.7,LogisticRegression(max_iter=10000),0.755,0.76,-0.24,0.758,-0.242,0.76,0,-1.0,5,5.0,5,5.0,0:00:00.035363,0:00:00,

8,15,1,0.95,LogisticRegression(max_iter=10000),0.84,0.831,-0.169,0.83,-0.17,0.831,0,-1.0,281,281.0,281,281.0,0:00:12.952543,0:00:00,

8,15,1,0.9,LogisticRegression(max_iter=10000),0.825,0.83,-0.17,0.83,-0.17,0.83,0,-1.0,84,84.0,84,84.0,0:00:02.145808,0:00:00,

8,15,1,0.85,LogisticRegression(max_iter=10000),0.81,0.815,-0.185,0.815,-0.185,0.815,0,-1.0,43,43.0,43,43.0,0:00:00.428818,0:00:00,

8,15,1,0.8,LogisticRegression(max_iter=10000),0.778,0.783,-0.217,0.783,-0.217,0.783,0,-1.0,25,25.0,25,25.0,0:00:00.220613,0:00:00,

8,15,1,0.75,LogisticRegression(max_iter=10000),0.754,0.76,-0.24,0.759,-0.241,0.76,0,-1.0,3,3.0,3,3.0,0:00:00.055001,0:00:00,

8,15,1,0.7,LogisticRegression(max_iter=10000),0.754,0.76,-0.24,0.759,-0.241,0.76,0,-1.0,1,1.0,1,1.0,0:00:00.025810,0:00:00,

16,5,1,0.95,LogisticRegression(max_iter=10000),0.826,0.827,-0.173,0.827,-0.173,0.827,0,-1.0,82,82.0,82,82.0,0:00:02.493661,0:00:00,

16,5,1,0.9,LogisticRegression(max_iter=10000),0.821,0.819,-0.181,0.819,-0.181,0.819,0,-1.0,45,45.0,45,45.0,0:00:00.684426,0:00:00,

16,5,1,0.85,LogisticRegression(max_iter=10000),0.817,0.818,-0.182,0.818,-0.182,0.818,0,-1.0,30,30.0,30,30.0,0:00:00.234847,0:00:00,

16,5,1,0.8,LogisticRegression(max_iter=10000),0.798,0.8,-0.2,0.8,-0.2,0.8,0,-1.0,22,22.0,22,22.0,0:00:00.142075,0:00:00,

16,5,1,0.75,LogisticRegression(max_iter=10000),0.758,0.767,-0.233,0.766,-0.234,0.767,0,-1.0,9,9.0,9,9.0,0:00:00.029342,0:00:00,

16,5,1,0.7,LogisticRegression(max_iter=10000),0.737,0.744,-0.256,0.741,-0.259,0.744,0,-1.0,4,4.0,4,4.0,0:00:00.050913,0:00:00,

16,10,1,0.95,LogisticRegression(max_iter=10000),0.845,0.837,-0.163,0.837,-0.163,0.837,0,-1.0,315,315.0,315,315.0,0:00:13.336499,0:00:00,

16,10,1,0.9,LogisticRegression(max_iter=10000),0.836,0.834,-0.166,0.834,-0.166,0.834,0,-1.0,146,146.0,146,146.0,0:00:05.497778,0:00:00,

16,10,1,0.85,LogisticRegression(max_iter=10000),0.824,0.825,-0.175,0.825,-0.175,0.825,0,-1.0,65,65.0,65,65.0,0:00:00.823668,0:00:00,

16,10,1,0.8,LogisticRegression(max_iter=10000),0.806,0.808,-0.192,0.808,-0.192,0.808,0,-1.0,34,34.0,34,34.0,0:00:00.234647,0:00:00,

16,10,1,0.75,LogisticRegression(max_iter=10000),0.796,0.798,-0.202,0.798,-0.202,0.798,0,-1.0,24,24.0,24,24.0,0:00:00.151917,0:00:00,

16,10,1,0.7,LogisticRegression(max_iter=10000),0.786,0.793,-0.207,0.793,-0.207,0.793,0,-1.0,11,11.0,11,11.0,0:00:00.146032,0:00:00,

16,15,1,0.95,LogisticRegression(max_iter=10000),0.842,0.833,-0.167,0.833,-0.167,0.833,0,-1.0,394,394.0,394,394.0,0:00:15.198702,0:00:00,

16,15,1,0.9,LogisticRegression(max_iter=10000),0.832,0.83,-0.17,0.83,-0.17,0.83,0,-1.0,93,93.0,93,93.0,0:00:02.387126,0:00:00,

16,15,1,0.85,LogisticRegression(max_iter=10000),0.796,0.799,-0.201,0.799,-0.201,0.799,0,-1.0,25,25.0,25,25.0,0:00:00.089711,0:00:00,

16,15,1,0.8,LogisticRegression(max_iter=10000),0.793,0.797,-0.203,0.797,-0.203,0.797,0,-1.0,22,22.0,22,22.0,0:00:00.076627,0:00:00,

16,15,1,0.75,LogisticRegression(max_iter=10000),0.788,0.795,-0.205,0.795,-0.205,0.795,0,-1.0,15,15.0,15,15.0,0:00:00.077158,0:00:00,

16,15,1,0.7,LogisticRegression(max_iter=10000),0.767,0.78,-0.22,0.779,-0.221,0.78,0,-1.0,4,4.0,4,4.0,0:00:00.040514,0:00:00,

32,5,1,0.95,LogisticRegression(max_iter=10000),0.834,0.831,-0.169,0.831,-0.169,0.831,0,-1.0,101,101.0,101,101.0,0:00:02.987761,0:00:00,

32,5,1,0.9,LogisticRegression(max_iter=10000),0.826,0.826,-0.174,0.826,-0.174,0.826,0,-1.0,60,60.0,60,60.0,0:00:00.692111,0:00:00,

32,5,1,0.85,LogisticRegression(max_iter=10000),0.821,0.82,-0.18,0.82,-0.18,0.82,0,-1.0,43,43.0,43,43.0,0:00:00.704890,0:00:00,

32,5,1,0.8,LogisticRegression(max_iter=10000),0.802,0.804,-0.196,0.804,-0.196,0.804,0,-1.0,28,28.0,28,28.0,0:00:00.200619,0:00:00,

32,5,1,0.75,LogisticRegression(max_iter=10000),0.791,0.799,-0.201,0.798,-0.202,0.799,0,-1.0,15,15.0,15,15.0,0:00:00.094623,0:00:00,

32,5,1,0.7,LogisticRegression(max_iter=10000),0.772,0.784,-0.216,0.784,-0.216,0.784,0,-1.0,9,9.0,9,9.0,0:00:00.049573,0:00:00,

32,10,1,0.95,LogisticRegression(max_iter=10000),0.844,0.833,-0.167,0.833,-0.167,0.833,0,-1.0,455,455.0,455,455.0,0:00:20.667655,0:00:00,

32,10,1,0.9,LogisticRegression(max_iter=10000),0.837,0.832,-0.168,0.832,-0.168,0.832,0,-1.0,149,149.0,149,149.0,0:00:03.880349,0:00:00,

32,10,1,0.85,LogisticRegression(max_iter=10000),0.825,0.822,-0.178,0.822,-0.178,0.822,0,-1.0,66,66.0,66,66.0,0:00:00.650476,0:00:00,

32,10,1,0.8,LogisticRegression(max_iter=10000),0.8,0.803,-0.197,0.803,-0.197,0.803,0,-1.0,25,25.0,25,25.0,0:00:00.164307,0:00:00,

32,10,1,0.75,LogisticRegression(max_iter=10000),0.793,0.797,-0.203,0.797,-0.203,0.797,0,-1.0,15,15.0,15,15.0,0:00:00.103717,0:00:00,

32,10,1,0.7,LogisticRegression(max_iter=10000),0.772,0.783,-0.217,0.783,-0.217,0.783,0,-1.0,7,7.0,7,7.0,0:00:00.089663,0:00:00,

32,15,1,0.95,LogisticRegression(max_iter=10000),0.85,0.835,-0.165,0.834,-0.166,0.835,0,-1.0,669,669.0,669,669.0,0:00:34.359466,0:00:00,

32,15,1,0.9,LogisticRegression(max_iter=10000),0.834,0.831,-0.169,0.831,-0.169,0.831,0,-1.0,167,167.0,167,167.0,0:00:06.359125,0:00:00,

32,15,1,0.85,LogisticRegression(max_iter=10000),0.824,0.823,-0.177,0.823,-0.177,0.823,0,-1.0,67,67.0,67,67.0,0:00:01.026378,0:00:00,

32,15,1,0.8,LogisticRegression(max_iter=10000),0.801,0.806,-0.194,0.806,-0.194,0.806,0,-1.0,25,25.0,25,25.0,0:00:00.328607,0:00:00,

32,15,1,0.75,LogisticRegression(max_iter=10000),0.79,0.796,-0.204,0.796,-0.204,0.796,0,-1.0,14,14.0,14,14.0,0:00:00.132456,0:00:00,

32,15,1,0.7,LogisticRegression(max_iter=10000),0.784,0.787,-0.213,0.786,-0.214,0.787,0,-1.0,10,10.0,10,10.0,0:00:00.088923,0:00:00,

Forest Size, Forest Depth, Patterns threshold, Edges Threshold, Learner, Train Accuracy, Test Accuracy, Test Accuracy (gain), F1_macro, F1_macro (gain), F1_micro, ROC_AUC, ROC_AUC (gain), Patterns Count, Patterns Ratio, Nodes Count, Nodes Ratio, Training Time, Pruning Time

Forest Size, Forest Depth, Patterns threshold, Edges Threshold, Learner, Train Accuracy, Test Accuracy, Test Accuracy (gain), F1_macro, F1_macro (gain), F1_micro, ROC_AUC, ROC_AUC (gain), Patterns Count, Patterns Ratio, Nodes Count, Nodes Ratio, Training Time, Pruning Time

1,5,1,0.95,LogisticRegression(max_iter=10000),0.795,0.799,-0.201,0.799,-0.201,0.799,0,-1.0,20,20.0,20,20.0,0:00:00.075195,0:00:00,

1,5,1,0.9,LogisticRegression(max_iter=10000),0.764,0.77,-0.23,0.77,-0.23,0.77,0,-1.0,15,15.0,15,15.0,0:00:00.068152,0:00:00,

1,5,1,0.85,LogisticRegression(max_iter=10000),0.761,0.769,-0.231,0.769,-0.231,0.769,0,-1.0,13,13.0,13,13.0,0:00:00.107027,0:00:00,

1,5,1,0.8,LogisticRegression(max_iter=10000),0.762,0.765,-0.235,0.765,-0.235,0.765,0,-1.0,12,12.0,12,12.0,0:00:00.076643,0:00:00,

1,5,1,0.75,LogisticRegression(max_iter=10000),0.75,0.761,-0.239,0.761,-0.239,0.761,0,-1.0,10,10.0,10,10.0,0:00:00.038620,0:00:00,

