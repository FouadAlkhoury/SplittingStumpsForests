Forest Size, Forest Depth, Patterns threshold, Edges Threshold, Learner, Train Accuracy, Test Accuracy, Test Accuracy (gain), F1_macro, F1_macro (gain), F1_micro, ROC_AUC, ROC_AUC (gain), Patterns Count, Patterns Ratio, Nodes Count, Nodes Ratio, Training Time, Pruning Time

64,5,1,1.0,LogisticRegression(max_iter=10000),0.919,0.897,0.0,0.901,0.0,0.897,0,0,482,1.0,482,1.0,0:00:41.836409,0:00:00,

64,5,1,0.95,LogisticRegression(max_iter=10000),0.907,0.894,-0.002,0.9,-0.002,0.894,0,0,366,0.759,366,0.759,0:00:28.205870,0:00:00,

64,5,1,0.9,LogisticRegression(max_iter=10000),0.886,0.872,-0.025,0.869,-0.032,0.872,0,0,237,0.492,237,0.492,0:00:16.347546,0:00:00,

64,5,1,0.85,LogisticRegression(max_iter=10000),0.881,0.871,-0.025,0.866,-0.035,0.871,0,0,175,0.363,175,0.363,0:00:10.409889,0:00:00,

64,5,1,0.8,LogisticRegression(max_iter=10000),0.852,0.847,-0.05,0.823,-0.078,0.847,0,0,112,0.232,112,0.232,0:00:06.553941,0:00:00,

64,5,1,0.75,LogisticRegression(max_iter=10000),0.794,0.796,-0.101,0.636,-0.265,0.796,0,0,58,0.12,58,0.12,0:00:04.086772,0:00:00,

64,5,1,0.7,LogisticRegression(max_iter=10000),0.789,0.789,-0.107,0.629,-0.272,0.789,0,0,46,0.095,46,0.095,0:00:03.075518,0:00:00,

64,5,1,0.65,LogisticRegression(max_iter=10000),0.782,0.784,-0.113,0.621,-0.28,0.784,0,0,27,0.056,27,0.056,0:00:03.582937,0:00:00,

64,10,1,1.0,LogisticRegression(max_iter=10000),0.973,0.905,0.0,0.917,0.0,0.905,0,0,2270,1.0,2270,1.0,0:05:25.389225,0:00:00,

64,10,1,0.95,LogisticRegression(max_iter=10000),0.956,0.906,0.001,0.919,0.002,0.906,0,0,1265,0.557,1265,0.557,0:02:44.403291,0:00:00,

64,10,1,0.9,LogisticRegression(max_iter=10000),0.934,0.903,-0.002,0.913,-0.004,0.903,0,0,620,0.273,620,0.273,0:01:02.935602,0:00:00,

64,10,1,0.85,LogisticRegression(max_iter=10000),0.915,0.905,0.0,0.913,-0.005,0.905,0,0,300,0.132,300,0.132,0:00:25.847103,0:00:00,

64,10,1,0.8,LogisticRegression(max_iter=10000),0.857,0.854,-0.05,0.823,-0.094,0.854,0,0,151,0.067,151,0.067,0:00:12.990570,0:00:00,

64,10,1,0.75,LogisticRegression(max_iter=10000),0.803,0.8,-0.104,0.646,-0.272,0.8,0,0,81,0.036,81,0.036,0:00:07.852147,0:00:00,

64,10,1,0.7,LogisticRegression(max_iter=10000),0.793,0.79,-0.115,0.636,-0.281,0.79,0,0,63,0.028,63,0.028,0:00:05.628119,0:00:00,

64,10,1,0.65,LogisticRegression(max_iter=10000),0.79,0.786,-0.119,0.632,-0.286,0.786,0,0,46,0.02,46,0.02,0:00:04.565749,0:00:00,

64,15,1,1.0,LogisticRegression(max_iter=10000),0.99,0.906,0.0,0.918,0.0,0.906,0,0,4187,1.0,4187,1.0,0:15:08.700591,0:00:00,

64,15,1,0.95,LogisticRegression(max_iter=10000),0.97,0.911,0.005,0.922,0.004,0.911,0,0,1990,0.475,1990,0.475,0:06:09.270434,0:00:00,

64,15,1,0.9,LogisticRegression(max_iter=10000),0.944,0.908,0.002,0.919,0.001,0.908,0,0,908,0.217,908,0.217,0:01:59.222533,0:00:00,

64,15,1,0.85,LogisticRegression(max_iter=10000),0.923,0.903,-0.003,0.91,-0.009,0.903,0,0,405,0.097,405,0.097,0:00:40.226943,0:00:00,

64,15,1,0.8,LogisticRegression(max_iter=10000),0.884,0.872,-0.034,0.867,-0.051,0.872,0,0,176,0.042,176,0.042,0:00:21.221035,0:00:00,

64,15,1,0.75,LogisticRegression(max_iter=10000),0.818,0.82,-0.086,0.678,-0.241,0.82,0,0,79,0.019,79,0.019,0:00:08.972104,0:00:00,

64,15,1,0.7,LogisticRegression(max_iter=10000),0.786,0.79,-0.116,0.635,-0.284,0.79,0,0,45,0.011,45,0.011,0:00:04.322625,0:00:00,

64,15,1,0.65,LogisticRegression(max_iter=10000),0.782,0.785,-0.121,0.631,-0.288,0.785,0,0,34,0.008,34,0.008,0:00:08.222708,0:00:00,

Forest Size, Forest Depth, Patterns threshold, Edges Threshold, Learner, Train Accuracy, Test Accuracy, Test Accuracy (gain), F1_macro, F1_macro (gain), F1_micro, ROC_AUC, ROC_AUC (gain), Patterns Count, Patterns Ratio, Nodes Count, Nodes Ratio, Training Time, Pruning Time

4,5,1,0.95,LogisticRegression(max_iter=10000),0.812,0.804,-0.196,0.799,-0.201,0.804,0,-1.0,44,44.0,44,44.0,0:00:03.008361,0:00:00,

4,5,1,0.9,LogisticRegression(max_iter=10000),0.79,0.782,-0.218,0.756,-0.244,0.782,0,-1.0,28,28.0,28,28.0,0:00:07.491713,0:00:00,

4,5,1,0.85,LogisticRegression(max_iter=10000),0.758,0.757,-0.243,0.729,-0.271,0.757,0,-1.0,18,18.0,18,18.0,0:00:06.926704,0:00:00,

4,5,1,0.8,LogisticRegression(max_iter=10000),0.72,0.719,-0.281,0.576,-0.424,0.719,0,-1.0,16,16.0,16,16.0,0:00:05.798648,0:00:00,

4,5,1,0.75,LogisticRegression(max_iter=10000),0.682,0.685,-0.315,0.529,-0.471,0.685,0,-1.0,11,11.0,11,11.0,0:00:03.979957,0:00:00,

4,5,1,0.7,LogisticRegression(max_iter=10000),0.668,0.669,-0.331,0.5,-0.5,0.669,0,-1.0,9,9.0,9,9.0,0:00:03.157994,0:00:00,

4,10,1,0.95,LogisticRegression(max_iter=10000),0.905,0.898,-0.102,0.904,-0.096,0.898,0,-1.0,145,145.0,145,145.0,0:00:17.501567,0:00:00,

4,10,1,0.9,LogisticRegression(max_iter=10000),0.883,0.879,-0.121,0.878,-0.122,0.879,0,-1.0,75,75.0,75,75.0,0:00:12.856660,0:00:00,

4,10,1,0.85,LogisticRegression(max_iter=10000),0.817,0.818,-0.182,0.772,-0.228,0.818,0,-1.0,36,36.0,36,36.0,0:00:07.018971,0:00:00,

4,10,1,0.8,LogisticRegression(max_iter=10000),0.761,0.761,-0.239,0.587,-0.413,0.761,0,-1.0,23,23.0,23,23.0,0:00:06.401473,0:00:00,

4,10,1,0.75,LogisticRegression(max_iter=10000),0.675,0.677,-0.323,0.506,-0.494,0.677,0,-1.0,14,14.0,14,14.0,0:00:04.230812,0:00:00,

4,10,1,0.7,LogisticRegression(max_iter=10000),0.675,0.677,-0.323,0.506,-0.494,0.677,0,-1.0,13,13.0,13,13.0,0:00:04.968494,0:00:00,

4,15,1,0.95,LogisticRegression(max_iter=10000),0.913,0.901,-0.099,0.908,-0.092,0.901,0,-1.0,217,217.0,217,217.0,0:00:27.396382,0:00:00,

4,15,1,0.9,LogisticRegression(max_iter=10000),0.9,0.889,-0.111,0.892,-0.108,0.889,0,-1.0,133,133.0,133,133.0,0:00:11.929901,0:00:00,

4,15,1,0.85,LogisticRegression(max_iter=10000),0.876,0.87,-0.13,0.875,-0.125,0.87,0,-1.0,68,68.0,68,68.0,0:00:08.494778,0:00:00,

4,15,1,0.8,LogisticRegression(max_iter=10000),0.753,0.752,-0.248,0.575,-0.425,0.752,0,-1.0,23,23.0,23,23.0,0:00:06.809801,0:00:00,

4,15,1,0.75,LogisticRegression(max_iter=10000),0.535,0.536,-0.464,0.319,-0.681,0.536,0,-1.0,7,7.0,7,7.0,0:00:03.578576,0:00:00,

4,15,1,0.7,LogisticRegression(max_iter=10000),0.535,0.536,-0.464,0.319,-0.681,0.536,0,-1.0,7,7.0,7,7.0,0:00:02.913571,0:00:00,

8,5,1,0.95,LogisticRegression(max_iter=10000),0.85,0.844,-0.156,0.837,-0.163,0.844,0,-1.0,70,70.0,70,70.0,0:00:15.660038,0:00:00,

8,5,1,0.9,LogisticRegression(max_iter=10000),0.83,0.829,-0.171,0.796,-0.204,0.829,0,-1.0,52,52.0,52,52.0,0:00:12.758067,0:00:00,

8,5,1,0.85,LogisticRegression(max_iter=10000),0.824,0.826,-0.174,0.793,-0.207,0.826,0,-1.0,41,41.0,41,41.0,0:00:09.662629,0:00:00,

8,5,1,0.8,LogisticRegression(max_iter=10000),0.784,0.787,-0.213,0.639,-0.361,0.787,0,-1.0,32,32.0,32,32.0,0:00:06.902755,0:00:00,

8,5,1,0.75,LogisticRegression(max_iter=10000),0.691,0.696,-0.304,0.518,-0.482,0.696,0,-1.0,15,15.0,15,15.0,0:00:03.646319,0:00:00,

8,5,1,0.7,LogisticRegression(max_iter=10000),0.689,0.694,-0.306,0.517,-0.483,0.694,0,-1.0,14,14.0,14,14.0,0:00:05.620204,0:00:00,

8,10,1,0.95,LogisticRegression(max_iter=10000),0.916,0.899,-0.101,0.905,-0.095,0.899,0,-1.0,271,271.0,271,271.0,0:00:26.580056,0:00:00,

8,10,1,0.9,LogisticRegression(max_iter=10000),0.889,0.889,-0.111,0.889,-0.111,0.889,0,-1.0,131,131.0,131,131.0,0:00:11.758789,0:00:00,

8,10,1,0.85,LogisticRegression(max_iter=10000),0.845,0.844,-0.156,0.81,-0.19,0.844,0,-1.0,67,67.0,67,67.0,0:00:08.293033,0:00:00,

8,10,1,0.8,LogisticRegression(max_iter=10000),0.781,0.782,-0.218,0.625,-0.375,0.782,0,-1.0,25,25.0,25,25.0,0:00:05.890408,0:00:00,

8,10,1,0.75,LogisticRegression(max_iter=10000),0.751,0.751,-0.249,0.571,-0.429,0.751,0,-1.0,16,16.0,16,16.0,0:00:03.801133,0:00:00,

8,10,1,0.7,LogisticRegression(max_iter=10000),0.751,0.751,-0.249,0.571,-0.429,0.751,0,-1.0,15,15.0,15,15.0,0:00:03.898769,0:00:00,

8,15,1,0.95,LogisticRegression(max_iter=10000),0.925,0.903,-0.097,0.911,-0.089,0.903,0,-1.0,423,423.0,423,423.0,0:00:43.772614,0:00:00,

8,15,1,0.9,LogisticRegression(max_iter=10000),0.909,0.898,-0.102,0.904,-0.096,0.898,0,-1.0,196,196.0,196,196.0,0:00:17.450208,0:00:00,

8,15,1,0.85,LogisticRegression(max_iter=10000),0.882,0.875,-0.125,0.873,-0.127,0.875,0,-1.0,66,66.0,66,66.0,0:00:06.012721,0:00:00,

8,15,1,0.8,LogisticRegression(max_iter=10000),0.798,0.798,-0.202,0.637,-0.363,0.798,0,-1.0,35,35.0,35,35.0,0:00:09.455099,0:00:00,

8,15,1,0.75,LogisticRegression(max_iter=10000),0.77,0.768,-0.232,0.607,-0.393,0.768,0,-1.0,17,17.0,17,17.0,0:00:04.473715,0:00:00,

8,15,1,0.7,LogisticRegression(max_iter=10000),0.71,0.709,-0.291,0.554,-0.446,0.709,0,-1.0,13,13.0,13,13.0,0:00:03.857281,0:00:00,

16,5,1,0.95,LogisticRegression(max_iter=10000),0.86,0.853,-0.147,0.83,-0.17,0.853,0,-1.0,112,112.0,112,112.0,0:00:10.942624,0:00:00,

16,5,1,0.9,LogisticRegression(max_iter=10000),0.855,0.85,-0.15,0.822,-0.178,0.85,0,-1.0,93,93.0,93,93.0,0:00:07.981300,0:00:00,

16,5,1,0.85,LogisticRegression(max_iter=10000),0.844,0.845,-0.155,0.827,-0.173,0.845,0,-1.0,69,69.0,69,69.0,0:00:07.102841,0:00:00,

16,5,1,0.8,LogisticRegression(max_iter=10000),0.837,0.838,-0.162,0.792,-0.208,0.838,0,-1.0,49,49.0,49,49.0,0:00:08.925860,0:00:00,

16,5,1,0.75,LogisticRegression(max_iter=10000),0.784,0.784,-0.216,0.621,-0.379,0.784,0,-1.0,30,30.0,30,30.0,0:00:06.863677,0:00:00,

16,5,1,0.7,LogisticRegression(max_iter=10000),0.764,0.765,-0.235,0.585,-0.415,0.765,0,-1.0,22,22.0,22,22.0,0:00:05.467187,0:00:00,

16,10,1,0.95,LogisticRegression(max_iter=10000),0.928,0.901,-0.099,0.91,-0.09,0.901,0,-1.0,453,453.0,453,453.0,0:01:02.204513,0:00:00,

16,10,1,0.9,LogisticRegression(max_iter=10000),0.91,0.9,-0.1,0.906,-0.094,0.9,0,-1.0,225,225.0,225,225.0,0:00:21.592467,0:00:00,

16,10,1,0.85,LogisticRegression(max_iter=10000),0.883,0.877,-0.123,0.878,-0.122,0.877,0,-1.0,110,110.0,110,110.0,0:00:10.721087,0:00:00,

16,10,1,0.8,LogisticRegression(max_iter=10000),0.835,0.837,-0.163,0.808,-0.192,0.837,0,-1.0,62,62.0,62,62.0,0:00:06.705153,0:00:00,

16,10,1,0.75,LogisticRegression(max_iter=10000),0.776,0.776,-0.224,0.635,-0.365,0.776,0,-1.0,33,33.0,33,33.0,0:00:07.604277,0:00:00,

16,10,1,0.7,LogisticRegression(max_iter=10000),0.773,0.77,-0.23,0.63,-0.37,0.77,0,-1.0,21,21.0,21,21.0,0:00:05.114154,0:00:00,

16,15,1,0.95,LogisticRegression(max_iter=10000),0.938,0.912,-0.088,0.922,-0.078,0.912,0,-1.0,657,657.0,657,657.0,0:01:16.757854,0:00:00,

16,15,1,0.9,LogisticRegression(max_iter=10000),0.919,0.907,-0.093,0.916,-0.084,0.907,0,-1.0,292,292.0,292,292.0,0:00:31.296017,0:00:00,

16,15,1,0.85,LogisticRegression(max_iter=10000),0.896,0.894,-0.106,0.897,-0.103,0.894,0,-1.0,107,107.0,107,107.0,0:00:10.710159,0:00:00,

16,15,1,0.8,LogisticRegression(max_iter=10000),0.837,0.84,-0.16,0.812,-0.188,0.84,0,-1.0,51,51.0,51,51.0,0:00:11.497718,0:00:00,

16,15,1,0.75,LogisticRegression(max_iter=10000),0.719,0.711,-0.289,0.578,-0.422,0.711,0,-1.0,27,27.0,27,27.0,0:00:07.236476,0:00:00,

16,15,1,0.7,LogisticRegression(max_iter=10000),0.713,0.711,-0.289,0.575,-0.425,0.711,0,-1.0,24,24.0,24,24.0,0:00:06.514287,0:00:00,

32,5,1,0.95,LogisticRegression(max_iter=10000),0.891,0.886,-0.114,0.888,-0.112,0.886,0,-1.0,202,202.0,202,202.0,0:00:20.798159,0:00:00,

32,5,1,0.9,LogisticRegression(max_iter=10000),0.86,0.86,-0.14,0.855,-0.145,0.86,0,-1.0,140,140.0,140,140.0,0:00:14.700947,0:00:00,

32,5,1,0.85,LogisticRegression(max_iter=10000),0.851,0.851,-0.149,0.813,-0.187,0.851,0,-1.0,118,118.0,118,118.0,0:00:13.148760,0:00:00,

32,5,1,0.8,LogisticRegression(max_iter=10000),0.847,0.846,-0.154,0.809,-0.191,0.846,0,-1.0,82,82.0,82,82.0,0:00:09.665211,0:00:00,

32,5,1,0.75,LogisticRegression(max_iter=10000),0.797,0.797,-0.203,0.633,-0.367,0.797,0,-1.0,50,50.0,50,50.0,0:00:05.765246,0:00:00,

32,5,1,0.7,LogisticRegression(max_iter=10000),0.792,0.793,-0.207,0.63,-0.37,0.793,0,-1.0,42,42.0,42,42.0,0:00:06.068597,0:00:00,

32,10,1,0.95,LogisticRegression(max_iter=10000),0.942,0.913,-0.087,0.924,-0.076,0.913,0,-1.0,834,834.0,834,834.0,0:01:59.171997,0:00:00,

32,10,1,0.9,LogisticRegression(max_iter=10000),0.925,0.906,-0.094,0.914,-0.086,0.906,0,-1.0,436,436.0,436,436.0,0:00:54.048851,0:00:00,

32,10,1,0.85,LogisticRegression(max_iter=10000),0.883,0.869,-0.131,0.861,-0.139,0.869,0,-1.0,200,200.0,200,200.0,0:00:21.718227,0:00:00,

32,10,1,0.8,LogisticRegression(max_iter=10000),0.809,0.804,-0.196,0.649,-0.351,0.804,0,-1.0,92,92.0,92,92.0,0:00:09.928013,0:00:00,

32,10,1,0.75,LogisticRegression(max_iter=10000),0.802,0.8,-0.2,0.644,-0.356,0.8,0,-1.0,48,48.0,48,48.0,0:00:05.532864,0:00:00,

32,10,1,0.7,LogisticRegression(max_iter=10000),0.797,0.797,-0.203,0.641,-0.359,0.797,0,-1.0,40,40.0,40,40.0,0:00:04.350380,0:00:00,

32,15,1,0.95,LogisticRegression(max_iter=10000),0.952,0.906,-0.094,0.917,-0.083,0.906,0,-1.0,1102,1102.0,1102,1102.0,0:03:27.875907,0:00:00,

32,15,1,0.9,LogisticRegression(max_iter=10000),0.931,0.912,-0.088,0.922,-0.078,0.912,0,-1.0,505,505.0,505,505.0,0:01:10.997654,0:00:00,

32,15,1,0.85,LogisticRegression(max_iter=10000),0.91,0.9,-0.1,0.905,-0.095,0.9,0,-1.0,229,229.0,229,229.0,0:00:24.852451,0:00:00,

32,15,1,0.8,LogisticRegression(max_iter=10000),0.852,0.851,-0.149,0.817,-0.183,0.851,0,-1.0,100,100.0,100,100.0,0:00:11.988346,0:00:00,

32,15,1,0.75,LogisticRegression(max_iter=10000),0.802,0.801,-0.199,0.652,-0.348,0.801,0,-1.0,45,45.0,45,45.0,0:00:07.845737,0:00:00,

32,15,1,0.7,LogisticRegression(max_iter=10000),0.782,0.781,-0.219,0.614,-0.386,0.781,0,-1.0,35,35.0,35,35.0,0:00:06.912134,0:00:00,

