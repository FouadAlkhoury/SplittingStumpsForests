Forest Size, Forest Depth, Patterns threshold, Edges Threshold, Learner, Train Accuracy, Test Accuracy, Test Accuracy (gain), F1_macro, F1_macro (gain), F1_micro, ROC_AUC, ROC_AUC (gain), Patterns Count, Patterns Ratio, Nodes Count, Nodes Ratio, Training Time, Pruning Time

64,5,1,1.0,LogisticRegression(max_iter=10000),0.83,0.807,0.0,0.66,0.0,0.807,0,0,1087,1.0,1087,1.0,0:01:13.826637,0:00:00,

64,5,1,0.95,LogisticRegression(max_iter=10000),0.827,0.809,0.002,0.659,-0.001,0.809,0,0,635,0.584,635,0.584,0:00:31.377885,0:00:00,

64,5,1,0.9,LogisticRegression(max_iter=10000),0.824,0.812,0.005,0.662,0.002,0.812,0,0,290,0.267,290,0.267,0:00:10.138041,0:00:00,

64,5,1,0.85,LogisticRegression(max_iter=10000),0.821,0.808,0.001,0.65,-0.01,0.808,0,0,54,0.05,54,0.05,0:00:00.997924,0:00:00,

64,5,1,0.8,LogisticRegression(max_iter=10000),0.819,0.809,0.002,0.642,-0.018,0.809,0,0,14,0.013,14,0.013,0:00:00.069128,0:00:00,

64,5,1,0.75,LogisticRegression(max_iter=10000),0.779,0.779,-0.028,0.438,-0.222,0.779,0,0,5,0.005,5,0.005,0:00:00.050852,0:00:00,

64,5,1,0.7,LogisticRegression(max_iter=10000),0.779,0.779,-0.028,0.438,-0.222,0.779,0,0,5,0.005,5,0.005,0:00:00.047766,0:00:00,

64,5,1,0.65,LogisticRegression(max_iter=10000),0.779,0.779,-0.028,0.438,-0.222,0.779,0,0,5,0.005,5,0.005,0:00:00.050437,0:00:00,

Forest Size, Forest Depth, Patterns threshold, Edges Threshold, Learner, Train Accuracy, Test Accuracy, Test Accuracy (gain), F1_macro, F1_macro (gain), F1_micro, ROC_AUC, ROC_AUC (gain), Patterns Count, Patterns Ratio, Nodes Count, Nodes Ratio, Training Time, Pruning Time

Forest Size, Forest Depth, Patterns threshold, Edges Threshold, Learner, Train Accuracy, Test Accuracy, Test Accuracy (gain), F1_macro, F1_macro (gain), F1_micro, ROC_AUC, ROC_AUC (gain), Patterns Count, Patterns Ratio, Nodes Count, Nodes Ratio, Training Time, Pruning Time

64,5,1,0.95,LogisticRegression(max_iter=10000),0.828,0.808,-0.192,0.658,-0.342,0.808,0,-1.0,656,656.0,656,656.0,0:00:38.442293,0:00:00,

64,5,1,0.9,LogisticRegression(max_iter=10000),0.822,0.807,-0.193,0.649,-0.351,0.807,0,-1.0,225,225.0,225,225.0,0:00:06.643910,0:00:00,

64,5,1,0.85,LogisticRegression(max_iter=10000),0.819,0.809,-0.191,0.644,-0.356,0.809,0,-1.0,50,50.0,50,50.0,0:00:01.152550,0:00:00,

64,5,1,0.8,LogisticRegression(max_iter=10000),0.819,0.809,-0.191,0.643,-0.357,0.809,0,-1.0,22,22.0,22,22.0,0:00:00.133621,0:00:00,

64,5,1,0.75,LogisticRegression(max_iter=10000),0.82,0.811,-0.189,0.646,-0.354,0.811,0,-1.0,16,16.0,16,16.0,0:00:00.091923,0:00:00,

64,5,1,0.7,LogisticRegression(max_iter=10000),0.779,0.779,-0.221,0.438,-0.562,0.779,0,-1.0,9,9.0,9,9.0,0:00:00.077485,0:00:00,

64,5,1,0.65,LogisticRegression(max_iter=10000),0.779,0.779,-0.221,0.438,-0.562,0.779,0,-1.0,9,9.0,9,9.0,0:00:00.078166,0:00:00,

64,10,1,0.95,LogisticRegression(max_iter=10000),0.865,0.78,-0.221,0.637,-0.363,0.78,0,-1.0,5717,5717.0,5717,5717.0,0:17:58.667956,0:00:00,

64,10,1,0.9,LogisticRegression(max_iter=10000),0.831,0.806,-0.194,0.654,-0.346,0.806,0,-1.0,1239,1239.0,1239,1239.0,0:01:44.529375,0:00:00,

64,10,1,0.85,LogisticRegression(max_iter=10000),0.822,0.81,-0.19,0.657,-0.343,0.81,0,-1.0,118,118.0,118,118.0,0:00:03.472952,0:00:00,

64,10,1,0.8,LogisticRegression(max_iter=10000),0.807,0.804,-0.196,0.636,-0.364,0.804,0,-1.0,22,22.0,22,22.0,0:00:00.173841,0:00:00,

64,10,1,0.75,LogisticRegression(max_iter=10000),0.779,0.779,-0.221,0.438,-0.562,0.779,0,-1.0,8,8.0,8,8.0,0:00:00.046189,0:00:00,

64,10,1,0.7,LogisticRegression(max_iter=10000),0.779,0.779,-0.221,0.438,-0.562,0.779,0,-1.0,7,7.0,7,7.0,0:00:00.042451,0:00:00,

64,10,1,0.65,LogisticRegression(max_iter=10000),0.779,0.779,-0.221,0.438,-0.562,0.779,0,-1.0,7,7.0,7,7.0,0:00:00.042520,0:00:00,

64,15,1,0.95,LogisticRegression(max_iter=10000),0.905,0.765,-0.235,0.627,-0.373,0.765,0,-1.0,11570,11570.0,11570,11570.0,0:57:46.875259,0:00:00,

64,15,1,0.9,LogisticRegression(max_iter=10000),0.841,0.799,-0.201,0.652,-0.348,0.799,0,-1.0,2388,2388.0,2388,2388.0,0:05:47.171737,0:00:00,

64,15,1,0.85,LogisticRegression(max_iter=10000),0.825,0.814,-0.186,0.666,-0.334,0.814,0,-1.0,404,404.0,404,404.0,0:00:23.717196,0:00:00,

64,15,1,0.8,LogisticRegression(max_iter=10000),0.821,0.81,-0.19,0.654,-0.346,0.81,0,-1.0,104,104.0,104,104.0,0:00:03.359070,0:00:00,

64,15,1,0.75,LogisticRegression(max_iter=10000),0.806,0.802,-0.198,0.636,-0.364,0.802,0,-1.0,34,34.0,34,34.0,0:00:00.612656,0:00:00,

64,15,1,0.7,LogisticRegression(max_iter=10000),0.799,0.793,-0.207,0.636,-0.364,0.793,0,-1.0,22,22.0,22,22.0,0:00:00.313728,0:00:00,

64,15,1,0.65,LogisticRegression(max_iter=10000),0.78,0.78,-0.22,0.456,-0.544,0.78,0,-1.0,19,19.0,19,19.0,0:00:00.370517,0:00:00,

Forest Size, Forest Depth, Patterns threshold, Edges Threshold, Learner, Train Accuracy, Test Accuracy, Test Accuracy (gain), F1_macro, F1_macro (gain), F1_micro, ROC_AUC, ROC_AUC (gain), Patterns Count, Patterns Ratio, Nodes Count, Nodes Ratio, Training Time, Pruning Time

16,5,1,0.95,LogisticRegression(max_iter=10000),0.823,0.811,-0.189,0.661,-0.339,0.811,0,-1.0,176,176.0,176,176.0,0:00:06.647663,0:00:00,

16,5,1,0.9,LogisticRegression(max_iter=10000),0.822,0.81,-0.19,0.656,-0.344,0.81,0,-1.0,83,83.0,83,83.0,0:00:02.639480,0:00:00,

16,5,1,0.85,LogisticRegression(max_iter=10000),0.821,0.811,-0.189,0.657,-0.343,0.811,0,-1.0,21,21.0,21,21.0,0:00:00.367117,0:00:00,

16,5,1,0.8,LogisticRegression(max_iter=10000),0.779,0.779,-0.221,0.438,-0.562,0.779,0,-1.0,3,3.0,3,3.0,0:00:00.080964,0:00:00,

16,5,1,0.75,LogisticRegression(max_iter=10000),0.779,0.779,-0.221,0.438,-0.562,0.779,0,-1.0,3,3.0,3,3.0,0:00:00.145176,0:00:00,

16,5,1,0.7,LogisticRegression(max_iter=10000),0.779,0.779,-0.221,0.438,-0.562,0.779,0,-1.0,1,1.0,1,1.0,0:00:00.071145,0:00:00,

16,10,1,0.95,LogisticRegression(max_iter=10000),0.833,0.804,-0.196,0.655,-0.345,0.804,0,-1.0,1655,1655.0,1655,1655.0,0:02:31.668781,0:00:00,

16,10,1,0.9,LogisticRegression(max_iter=10000),0.826,0.811,-0.189,0.664,-0.336,0.811,0,-1.0,563,563.0,563,563.0,0:00:28.649909,0:00:00,

16,10,1,0.85,LogisticRegression(max_iter=10000),0.819,0.811,-0.189,0.657,-0.343,0.811,0,-1.0,47,47.0,47,47.0,0:00:00.417135,0:00:00,

16,10,1,0.8,LogisticRegression(max_iter=10000),0.82,0.81,-0.19,0.655,-0.345,0.81,0,-1.0,25,25.0,25,25.0,0:00:00.137048,0:00:00,

16,10,1,0.75,LogisticRegression(max_iter=10000),0.779,0.779,-0.221,0.438,-0.562,0.779,0,-1.0,2,2.0,2,2.0,0:00:00.048021,0:00:00,

16,10,1,0.7,LogisticRegression(max_iter=10000),0.779,0.779,-0.221,0.438,-0.562,0.779,0,-1.0,2,2.0,2,2.0,0:00:00.053836,0:00:00,

16,15,1,0.95,LogisticRegression(max_iter=10000),0.85,0.789,-0.211,0.639,-0.361,0.789,0,-1.0,3787,3787.0,3787,3787.0,0:09:07.623053,0:00:00,

16,15,1,0.9,LogisticRegression(max_iter=10000),0.829,0.805,-0.195,0.65,-0.35,0.805,0,-1.0,1037,1037.0,1037,1037.0,0:01:14.698699,0:00:00,

16,15,1,0.85,LogisticRegression(max_iter=10000),0.822,0.81,-0.19,0.658,-0.342,0.81,0,-1.0,191,191.0,191,191.0,0:00:05.497018,0:00:00,

16,15,1,0.8,LogisticRegression(max_iter=10000),0.818,0.809,-0.191,0.646,-0.354,0.809,0,-1.0,26,26.0,26,26.0,0:00:00.107987,0:00:00,

16,15,1,0.75,LogisticRegression(max_iter=10000),0.779,0.779,-0.221,0.438,-0.562,0.779,0,-1.0,4,4.0,4,4.0,0:00:00.045725,0:00:00,

16,15,1,0.7,LogisticRegression(max_iter=10000),0.779,0.779,-0.221,0.438,-0.562,0.779,0,-1.0,4,4.0,4,4.0,0:00:00.048942,0:00:00,

32,5,1,0.95,LogisticRegression(max_iter=10000),0.825,0.81,-0.19,0.658,-0.342,0.81,0,-1.0,386,386.0,386,386.0,0:00:23.015099,0:00:00,

32,5,1,0.9,LogisticRegression(max_iter=10000),0.823,0.811,-0.189,0.661,-0.339,0.811,0,-1.0,168,168.0,168,168.0,0:00:05.208494,0:00:00,

32,5,1,0.85,LogisticRegression(max_iter=10000),0.821,0.809,-0.191,0.654,-0.346,0.809,0,-1.0,47,47.0,47,47.0,0:00:00.992474,0:00:00,

32,5,1,0.8,LogisticRegression(max_iter=10000),0.79,0.783,-0.217,0.55,-0.45,0.783,0,-1.0,7,7.0,7,7.0,0:00:00.037683,0:00:00,

32,5,1,0.75,LogisticRegression(max_iter=10000),0.779,0.779,-0.221,0.438,-0.562,0.779,0,-1.0,3,3.0,3,3.0,0:00:00.048865,0:00:00,

32,5,1,0.7,LogisticRegression(max_iter=10000),0.779,0.779,-0.221,0.438,-0.562,0.779,0,-1.0,3,3.0,3,3.0,0:00:00.058494,0:00:00,

32,10,1,0.95,LogisticRegression(max_iter=10000),0.851,0.788,-0.212,0.642,-0.358,0.788,0,-1.0,3586,3586.0,3586,3586.0,0:08:32.584550,0:00:00,

32,10,1,0.9,LogisticRegression(max_iter=10000),0.83,0.808,-0.192,0.656,-0.344,0.808,0,-1.0,901,901.0,901,901.0,0:00:59.730741,0:00:00,

32,10,1,0.85,LogisticRegression(max_iter=10000),0.823,0.811,-0.189,0.661,-0.339,0.811,0,-1.0,111,111.0,111,111.0,0:00:03.521800,0:00:00,

32,10,1,0.8,LogisticRegression(max_iter=10000),0.808,0.804,-0.196,0.64,-0.36,0.804,0,-1.0,29,29.0,29,29.0,0:00:00.247329,0:00:00,

32,10,1,0.75,LogisticRegression(max_iter=10000),0.79,0.788,-0.212,0.572,-0.428,0.788,0,-1.0,11,11.0,11,11.0,0:00:00.062334,0:00:00,

32,10,1,0.7,LogisticRegression(max_iter=10000),0.79,0.788,-0.212,0.572,-0.428,0.788,0,-1.0,11,11.0,11,11.0,0:00:00.060249,0:00:00,

32,15,1,0.95,LogisticRegression(max_iter=10000),0.86,0.781,-0.219,0.636,-0.364,0.781,0,-1.0,5093,5093.0,5093,5093.0,0:15:48.352017,0:00:00,

32,15,1,0.9,LogisticRegression(max_iter=10000),0.829,0.807,-0.193,0.656,-0.344,0.807,0,-1.0,857,857.0,857,857.0,0:01:00.946549,0:00:00,

32,15,1,0.85,LogisticRegression(max_iter=10000),0.797,0.796,-0.204,0.598,-0.402,0.796,0,-1.0,11,11.0,11,11.0,0:00:00.280503,0:00:00,

32,15,1,0.8,LogisticRegression(max_iter=10000),0.778,0.778,-0.222,0.446,-0.554,0.778,0,-1.0,6,6.0,6,6.0,0:00:00.064394,0:00:00,

32,15,1,0.75,LogisticRegression(max_iter=10000),0.778,0.778,-0.222,0.446,-0.554,0.778,0,-1.0,5,5.0,5,5.0,0:00:00.067836,0:00:00,

32,15,1,0.7,LogisticRegression(max_iter=10000),0.779,0.779,-0.221,0.438,-0.562,0.779,0,-1.0,1,1.0,1,1.0,0:00:00.059921,0:00:00,

