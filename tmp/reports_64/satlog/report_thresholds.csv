Forest Size, Forest Depth, Patterns threshold, Edges Threshold, Learner, Train Accuracy, Test Accuracy, Test Accuracy (gain), F1_macro, F1_macro (gain), F1_micro, ROC_AUC, ROC_AUC (gain), Patterns Count, Patterns Ratio, Nodes Count, Nodes Ratio, Training Time, Pruning Time

64,5,1,1.0,LogisticRegression(max_iter=10000),0.347,0.322,0.0,0.235,0.0,0.322,0,0,64,1.0,1886,1.0,0:00:02.747857,0:00:00,

64,5,1,0.95,LogisticRegression(max_iter=10000),0.311,0.298,-0.024,0.192,-0.043,0.298,0,0,202,3.156,1601,0.849,0:00:04.811113,0:00:00,

64,5,1,0.9,LogisticRegression(max_iter=10000),0.242,0.23,-0.091,0.062,-0.172,0.23,0,0,302,4.719,1383,0.733,0:00:00.178154,0:00:00,

64,5,1,0.85,LogisticRegression(max_iter=10000),0.475,0.453,0.132,0.313,0.078,0.453,0,0,367,5.734,1200,0.636,0:00:02.241086,0:00:00,

64,5,1,0.8,LogisticRegression(max_iter=10000),0.666,0.622,0.3,0.443,0.208,0.622,0,0,445,6.953,950,0.504,0:00:09.292670,0:00:00,

64,5,1,0.75,LogisticRegression(max_iter=10000),0.755,0.708,0.386,0.601,0.366,0.708,0,0,453,7.078,707,0.375,0:00:07.235270,0:00:00,

64,5,1,0.7,LogisticRegression(max_iter=10000),0.68,0.63,0.309,0.494,0.26,0.63,0,0,382,5.969,506,0.268,0:00:04.020801,0:00:00,

64,5,1,0.65,LogisticRegression(max_iter=10000),0.493,0.457,0.136,0.356,0.121,0.457,0,0,303,4.734,352,0.187,0:00:01.258900,0:00:00,

64,5,1,0.6,LogisticRegression(max_iter=10000),0.475,0.438,0.117,0.316,0.081,0.438,0,0,225,3.516,238,0.126,0:00:01.057794,0:00:00,

64,10,1,1.0,LogisticRegression(max_iter=10000),0.407,0.398,0.0,0.352,0.0,0.398,0,0,64,1.0,13314,1.0,0:00:13.997445,0:00:00,

64,10,1,0.95,LogisticRegression(max_iter=10000),0.242,0.23,-0.167,0.062,-0.29,0.23,0,0,1405,21.953,11568,0.869,0:00:01.219714,0:00:00,

64,10,1,0.9,LogisticRegression(max_iter=10000),0.242,0.23,-0.167,0.062,-0.29,0.23,0,0,2320,36.25,10039,0.754,0:00:01.262480,0:00:00,

64,10,1,0.85,LogisticRegression(max_iter=10000),0.427,0.406,0.008,0.218,-0.134,0.406,0,0,2852,44.562,8569,0.644,0:00:10.326131,0:00:00,

64,10,1,0.8,LogisticRegression(max_iter=10000),0.709,0.676,0.278,0.543,0.191,0.676,0,0,3240,50.625,7440,0.559,0:00:30.001578,0:00:00,

64,10,1,0.75,LogisticRegression(max_iter=10000),0.743,0.71,0.312,0.601,0.248,0.71,0,0,3330,52.031,6216,0.467,0:00:43.368411,0:00:00,

64,10,1,0.7,LogisticRegression(max_iter=10000),0.559,0.532,0.134,0.46,0.107,0.532,0,0,3102,48.469,4791,0.36,0:00:13.257000,0:00:00,

64,10,1,0.65,LogisticRegression(max_iter=10000),0.506,0.476,0.078,0.369,0.016,0.476,0,0,2457,38.391,3255,0.244,0:00:13.255066,0:00:00,

64,10,1,0.6,LogisticRegression(max_iter=10000),0.586,0.562,0.165,0.479,0.126,0.562,0,0,2128,33.25,2568,0.193,0:00:10.576684,0:00:00,

64,15,1,1.0,LogisticRegression(max_iter=10000),0.328,0.312,0.0,0.216,0.0,0.312,0,0,64,1.0,21070,1.0,0:00:21.411159,0:00:00,

64,15,1,0.95,LogisticRegression(max_iter=10000),0.242,0.23,-0.081,0.062,-0.153,0.23,0,0,2352,36.75,18471,0.877,0:00:01.890906,0:00:00,

64,15,1,0.9,LogisticRegression(max_iter=10000),0.242,0.23,-0.081,0.062,-0.153,0.23,0,0,3766,58.844,16312,0.774,0:00:01.778476,0:00:00,

64,15,1,0.85,LogisticRegression(max_iter=10000),0.242,0.23,-0.081,0.062,-0.153,0.23,0,0,4671,72.984,14097,0.669,0:00:01.642738,0:00:00,

64,15,1,0.8,LogisticRegression(max_iter=10000),0.696,0.667,0.356,0.523,0.307,0.667,0,0,5282,82.531,12490,0.593,0:00:46.805382,0:00:00,

64,15,1,0.75,LogisticRegression(max_iter=10000),0.696,0.654,0.342,0.518,0.302,0.654,0,0,5477,85.578,10652,0.506,0:01:16.449927,0:00:00,

64,15,1,0.7,LogisticRegression(max_iter=10000),0.51,0.48,0.168,0.383,0.167,0.48,0,0,5221,81.578,8323,0.395,0:00:32.960914,0:00:00,

64,15,1,0.65,LogisticRegression(max_iter=10000),0.517,0.486,0.174,0.389,0.173,0.486,0,0,4174,65.219,5498,0.261,0:00:24.638052,0:00:00,

64,15,1,0.6,LogisticRegression(max_iter=10000),0.505,0.476,0.164,0.372,0.156,0.476,0,0,3766,58.844,4635,0.22,0:00:14.544107,0:00:00,

Forest Size, Forest Depth, Patterns threshold, Edges Threshold, Learner, Train Accuracy, Test Accuracy, Test Accuracy (gain), F1_macro, F1_macro (gain), F1_micro, ROC_AUC, ROC_AUC (gain), Patterns Count, Patterns Ratio, Nodes Count, Nodes Ratio, Training Time, Pruning Time

Forest Size, Forest Depth, Patterns threshold, Edges Threshold, Learner, Train Accuracy, Test Accuracy, Test Accuracy (gain), F1_macro, F1_macro (gain), F1_micro, ROC_AUC, ROC_AUC (gain), Patterns Count, Patterns Ratio, Nodes Count, Nodes Ratio, Training Time, Pruning Time

16,5,1,0.8,LogisticRegression(max_iter=10000),0.684,0.658,0.658,0.502,0.502,0.658,0,0.0,119,119.0,242,242.0,0:00:00.826354,0:00:00,

16,5,1,0.775,LogisticRegression(max_iter=10000),0.7,0.672,0.672,0.535,0.535,0.672,0,0.0,118,118.0,208,208.0,0:00:01.087839,0:00:00,

16,5,1,0.75,LogisticRegression(max_iter=10000),0.657,0.623,0.623,0.443,0.443,0.623,0,0.0,112,112.0,178,178.0,0:00:00.891723,0:00:00,

16,5,1,0.725,LogisticRegression(max_iter=10000),0.452,0.426,0.426,0.234,0.234,0.426,0,0.0,100,100.0,154,154.0,0:00:00.323586,0:00:00,

16,5,1,0.7,LogisticRegression(max_iter=10000),0.451,0.427,0.427,0.234,0.234,0.427,0,0.0,99,99.0,137,137.0,0:00:00.441598,0:00:00,

16,5,1,0.675,LogisticRegression(max_iter=10000),0.462,0.441,0.441,0.287,0.287,0.441,0,0.0,96,96.0,120,120.0,0:00:00.642456,0:00:00,

16,5,1,0.65,LogisticRegression(max_iter=10000),0.467,0.45,0.45,0.306,0.306,0.45,0,0.0,89,89.0,106,106.0,0:00:00.536608,0:00:00,

16,5,1,0.625,LogisticRegression(max_iter=10000),0.458,0.434,0.434,0.272,0.272,0.434,0,0.0,72,72.0,82,82.0,0:00:00.326733,0:00:00,

16,5,1,0.6,LogisticRegression(max_iter=10000),0.446,0.424,0.424,0.222,0.222,0.424,0,0.0,56,56.0,63,63.0,0:00:00.231425,0:00:00,

16,5,1,0.575,LogisticRegression(max_iter=10000),0.242,0.23,0.23,0.062,0.062,0.23,0,0.0,39,39.0,43,43.0,0:00:00.014137,0:00:00,

16,5,1,0.55,LogisticRegression(max_iter=10000),0.242,0.23,0.23,0.062,0.062,0.23,0,0.0,24,24.0,27,27.0,0:00:00.010665,0:00:00,

16,10,1,0.8,LogisticRegression(max_iter=10000),0.603,0.574,0.574,0.353,0.353,0.574,0,0.0,774,774.0,1746,1746.0,0:00:00.951802,0:00:00,

16,10,1,0.775,LogisticRegression(max_iter=10000),0.642,0.604,0.604,0.418,0.418,0.604,0,0.0,776,776.0,1527,1527.0,0:00:04.047198,0:00:00,

16,10,1,0.75,LogisticRegression(max_iter=10000),0.677,0.63,0.63,0.466,0.466,0.63,0,0.0,785,785.0,1444,1444.0,0:00:04.762868,0:00:00,

16,10,1,0.725,LogisticRegression(max_iter=10000),0.664,0.62,0.62,0.458,0.458,0.62,0,0.0,733,733.0,1213,1213.0,0:00:03.302297,0:00:00,

16,10,1,0.7,LogisticRegression(max_iter=10000),0.468,0.432,0.432,0.296,0.296,0.432,0,0.0,718,718.0,1100,1100.0,0:00:01.834148,0:00:00,

16,10,1,0.675,LogisticRegression(max_iter=10000),0.468,0.432,0.432,0.296,0.296,0.432,0,0.0,694,694.0,1017,1017.0,0:00:01.564832,0:00:00,

16,10,1,0.65,LogisticRegression(max_iter=10000),0.467,0.432,0.432,0.289,0.289,0.432,0,0.0,574,574.0,747,747.0,0:00:01.222610,0:00:00,

16,10,1,0.625,LogisticRegression(max_iter=10000),0.46,0.426,0.426,0.277,0.277,0.426,0,0.0,543,543.0,684,684.0,0:00:01.126947,0:00:00,

16,10,1,0.6,LogisticRegression(max_iter=10000),0.454,0.419,0.419,0.262,0.262,0.419,0,0.0,495,495.0,604,604.0,0:00:00.830734,0:00:00,

16,10,1,0.575,LogisticRegression(max_iter=10000),0.446,0.422,0.422,0.265,0.265,0.422,0,0.0,413,413.0,470,470.0,0:00:00.566536,0:00:00,

16,10,1,0.55,LogisticRegression(max_iter=10000),0.417,0.395,0.395,0.189,0.189,0.395,0,0.0,333,333.0,366,366.0,0:00:00.170890,0:00:00,

32,5,1,0.8,LogisticRegression(max_iter=10000),0.643,0.61,0.61,0.4,0.4,0.61,0,0.0,214,214.0,467,467.0,0:00:02.287697,0:00:00,

32,5,1,0.775,LogisticRegression(max_iter=10000),0.671,0.622,0.622,0.463,0.463,0.622,0,0.0,217,217.0,406,406.0,0:00:03.082412,0:00:00,

32,5,1,0.75,LogisticRegression(max_iter=10000),0.675,0.626,0.626,0.463,0.463,0.626,0,0.0,229,229.0,346,346.0,0:00:02.843907,0:00:00,

32,5,1,0.725,LogisticRegression(max_iter=10000),0.673,0.627,0.627,0.463,0.463,0.627,0,0.0,206,206.0,276,276.0,0:00:01.911564,0:00:00,

32,5,1,0.7,LogisticRegression(max_iter=10000),0.473,0.427,0.427,0.298,0.298,0.427,0,0.0,185,185.0,230,230.0,0:00:00.967583,0:00:00,

32,5,1,0.675,LogisticRegression(max_iter=10000),0.473,0.427,0.427,0.298,0.298,0.427,0,0.0,165,165.0,198,198.0,0:00:00.846401,0:00:00,

32,5,1,0.65,LogisticRegression(max_iter=10000),0.464,0.422,0.422,0.279,0.279,0.422,0,0.0,142,142.0,160,160.0,0:00:00.717580,0:00:00,

32,5,1,0.625,LogisticRegression(max_iter=10000),0.463,0.424,0.424,0.278,0.278,0.424,0,0.0,116,116.0,129,129.0,0:00:00.607474,0:00:00,

32,5,1,0.6,LogisticRegression(max_iter=10000),0.464,0.432,0.432,0.295,0.295,0.432,0,0.0,97,97.0,103,103.0,0:00:00.464874,0:00:00,

32,5,1,0.575,LogisticRegression(max_iter=10000),0.46,0.429,0.429,0.29,0.29,0.429,0,0.0,69,69.0,72,72.0,0:00:00.127219,0:00:00,

32,5,1,0.55,LogisticRegression(max_iter=10000),0.439,0.414,0.414,0.22,0.22,0.414,0,0.0,44,44.0,45,45.0,0:00:00.052161,0:00:00,

32,10,1,0.8,LogisticRegression(max_iter=10000),0.652,0.626,0.626,0.459,0.459,0.626,0,0.0,1636,1636.0,3638,3638.0,0:00:06.730141,0:00:00,

32,10,1,0.775,LogisticRegression(max_iter=10000),0.672,0.631,0.631,0.472,0.472,0.631,0,0.0,1659,1659.0,3219,3219.0,0:00:14.255236,0:00:00,

32,10,1,0.75,LogisticRegression(max_iter=10000),0.663,0.62,0.62,0.442,0.442,0.62,0,0.0,1674,1674.0,3074,3074.0,0:00:13.276492,0:00:00,

32,10,1,0.725,LogisticRegression(max_iter=10000),0.684,0.636,0.636,0.479,0.479,0.636,0,0.0,1591,1591.0,2590,2590.0,0:00:21.346944,0:00:00,

32,10,1,0.7,LogisticRegression(max_iter=10000),0.481,0.442,0.442,0.326,0.326,0.442,0,0.0,1555,1555.0,2366,2366.0,0:00:07.076116,0:00:00,

32,10,1,0.675,LogisticRegression(max_iter=10000),0.482,0.446,0.446,0.331,0.331,0.446,0,0.0,1519,1519.0,2177,2177.0,0:00:07.186040,0:00:00,

32,10,1,0.65,LogisticRegression(max_iter=10000),0.481,0.444,0.444,0.327,0.327,0.444,0,0.0,1209,1209.0,1582,1582.0,0:00:04.967512,0:00:00,

32,10,1,0.625,LogisticRegression(max_iter=10000),0.476,0.443,0.443,0.318,0.318,0.443,0,0.0,1137,1137.0,1430,1430.0,0:00:04.982892,0:00:00,

32,10,1,0.6,LogisticRegression(max_iter=10000),0.477,0.44,0.44,0.313,0.313,0.44,0,0.0,1035,1035.0,1253,1253.0,0:00:03.949419,0:00:00,

32,10,1,0.575,LogisticRegression(max_iter=10000),0.471,0.436,0.436,0.304,0.304,0.436,0,0.0,839,839.0,941,941.0,0:00:05.841065,0:00:00,

32,10,1,0.55,LogisticRegression(max_iter=10000),0.44,0.413,0.413,0.263,0.263,0.413,0,0.0,685,685.0,742,742.0,0:00:00.600236,0:00:00,

Forest Size, Forest Depth, Patterns threshold, Edges Threshold, Learner, Train Accuracy, Test Accuracy, Test Accuracy (gain), F1_macro, F1_macro (gain), F1_micro, ROC_AUC, ROC_AUC (gain), Patterns Count, Patterns Ratio, Nodes Count, Nodes Ratio, Training Time, Pruning Time

16,5,1,0.85,MultinomialNB(),0.242,0.23,0.23,0.062,0.062,0.23,0,0.0,96,96.0,284,284.0,0:00:00.007673,0:00:00,

16,5,1,0.8,MultinomialNB(),0.613,0.581,0.581,0.356,0.356,0.581,0,0.0,105,105.0,229,229.0,0:00:00.008482,0:00:00,

16,5,1,0.775,MultinomialNB(),0.633,0.6,0.6,0.402,0.402,0.6,0,0.0,112,112.0,193,193.0,0:00:00.007732,0:00:00,

16,5,1,0.75,MultinomialNB(),0.639,0.606,0.606,0.396,0.396,0.606,0,0.0,110,110.0,161,161.0,0:00:00.007353,0:00:00,

16,5,1,0.725,MultinomialNB(),0.436,0.43,0.43,0.198,0.198,0.43,0,0.0,96,96.0,135,135.0,0:00:00.008232,0:00:00,

16,5,1,0.7,MultinomialNB(),0.434,0.429,0.429,0.197,0.197,0.429,0,0.0,94,94.0,118,118.0,0:00:00.006371,0:00:00,

16,5,1,0.675,MultinomialNB(),0.434,0.429,0.429,0.197,0.197,0.429,0,0.0,87,87.0,101,101.0,0:00:00.005562,0:00:00,

16,5,1,0.65,MultinomialNB(),0.437,0.43,0.43,0.198,0.198,0.43,0,0.0,71,71.0,79,79.0,0:00:00.004724,0:00:00,

16,5,1,0.625,MultinomialNB(),0.434,0.428,0.428,0.197,0.197,0.428,0,0.0,59,59.0,64,64.0,0:00:00.006927,0:00:00,

16,5,1,0.6,MultinomialNB(),0.436,0.428,0.428,0.198,0.198,0.428,0,0.0,51,51.0,53,53.0,0:00:00.003804,0:00:00,

16,5,1,0.575,MultinomialNB(),0.435,0.425,0.425,0.198,0.198,0.425,0,0.0,37,37.0,38,38.0,0:00:00.004255,0:00:00,

16,5,1,0.55,MultinomialNB(),0.242,0.23,0.23,0.062,0.062,0.23,0,0.0,19,19.0,20,20.0,0:00:00.003190,0:00:00,

16,10,1,0.85,MultinomialNB(),0.242,0.23,0.23,0.062,0.062,0.23,0,0.0,682,682.0,2101,2101.0,0:00:00.057842,0:00:00,

16,10,1,0.8,MultinomialNB(),0.633,0.6,0.6,0.368,0.368,0.6,0,0.0,778,778.0,1824,1824.0,0:00:00.052974,0:00:00,

16,10,1,0.775,MultinomialNB(),0.639,0.606,0.606,0.373,0.373,0.606,0,0.0,796,796.0,1627,1627.0,0:00:00.051843,0:00:00,

16,10,1,0.75,MultinomialNB(),0.645,0.616,0.616,0.378,0.378,0.616,0,0.0,823,823.0,1536,1536.0,0:00:00.046778,0:00:00,

16,10,1,0.725,MultinomialNB(),0.432,0.43,0.43,0.198,0.198,0.43,0,0.0,772,772.0,1293,1293.0,0:00:00.041816,0:00:00,

16,10,1,0.7,MultinomialNB(),0.432,0.43,0.43,0.198,0.198,0.43,0,0.0,754,754.0,1181,1181.0,0:00:00.037859,0:00:00,

16,10,1,0.675,MultinomialNB(),0.432,0.43,0.43,0.198,0.198,0.43,0,0.0,736,736.0,1083,1083.0,0:00:00.044585,0:00:00,

16,10,1,0.65,MultinomialNB(),0.432,0.43,0.43,0.198,0.198,0.43,0,0.0,609,609.0,812,812.0,0:00:00.035867,0:00:00,

16,10,1,0.625,MultinomialNB(),0.432,0.43,0.43,0.198,0.198,0.43,0,0.0,580,580.0,747,747.0,0:00:00.027568,0:00:00,

16,10,1,0.6,MultinomialNB(),0.436,0.429,0.429,0.198,0.198,0.429,0,0.0,518,518.0,644,644.0,0:00:00.024980,0:00:00,

16,10,1,0.575,MultinomialNB(),0.428,0.418,0.418,0.198,0.198,0.418,0,0.0,417,417.0,483,483.0,0:00:00.017162,0:00:00,

16,10,1,0.55,MultinomialNB(),0.242,0.23,0.23,0.062,0.062,0.23,0,0.0,340,340.0,376,376.0,0:00:00.014800,0:00:00,

32,5,1,0.85,MultinomialNB(),0.242,0.23,0.23,0.062,0.062,0.23,0,0.0,178,178.0,560,560.0,0:00:00.023197,0:00:00,

32,5,1,0.8,MultinomialNB(),0.664,0.628,0.628,0.442,0.442,0.628,0,0.0,213,213.0,454,454.0,0:00:00.017063,0:00:00,

32,5,1,0.775,MultinomialNB(),0.641,0.61,0.61,0.438,0.438,0.61,0,0.0,216,216.0,392,392.0,0:00:00.015653,0:00:00,

32,5,1,0.75,MultinomialNB(),0.648,0.612,0.612,0.449,0.449,0.612,0,0.0,215,215.0,331,331.0,0:00:00.013860,0:00:00,

32,5,1,0.725,MultinomialNB(),0.646,0.614,0.614,0.448,0.448,0.614,0,0.0,191,191.0,251,251.0,0:00:00.010817,0:00:00,

32,5,1,0.7,MultinomialNB(),0.511,0.488,0.488,0.362,0.362,0.488,0,0.0,177,177.0,214,214.0,0:00:00.011932,0:00:00,

32,5,1,0.675,MultinomialNB(),0.434,0.425,0.425,0.195,0.195,0.425,0,0.0,168,168.0,195,195.0,0:00:00.008834,0:00:00,

32,5,1,0.65,MultinomialNB(),0.436,0.43,0.43,0.198,0.198,0.43,0,0.0,144,144.0,163,163.0,0:00:00.007783,0:00:00,

Forest Size, Forest Depth, Patterns threshold, Edges Threshold, Learner, Train Accuracy, Test Accuracy, Test Accuracy (gain), F1_macro, F1_macro (gain), F1_micro, ROC_AUC, ROC_AUC (gain), Patterns Count, Patterns Ratio, Nodes Count, Nodes Ratio, Training Time, Pruning Time

16,5,1,0.85,LinearSVC(max_iter=10000),0.428,0.401,0.401,0.208,0.208,0.401,0,0.0,97,97.0,287,287.0,0:00:00.053228,0:00:00,

16,5,1,0.8,LinearSVC(max_iter=10000),0.646,0.617,0.617,0.38,0.38,0.617,0,0.0,124,124.0,230,230.0,0:00:00.134491,0:00:00,

16,5,1,0.775,LinearSVC(max_iter=10000),0.652,0.62,0.62,0.398,0.398,0.62,0,0.0,126,126.0,198,198.0,0:00:00.204248,0:00:00,

16,5,1,0.75,LinearSVC(max_iter=10000),0.649,0.606,0.606,0.403,0.403,0.606,0,0.0,128,128.0,179,179.0,0:00:00.296716,0:00:00,

16,5,1,0.725,LinearSVC(max_iter=10000),0.648,0.606,0.606,0.391,0.391,0.606,0,0.0,114,114.0,144,144.0,0:00:00.186804,0:00:00,

16,5,1,0.7,LinearSVC(max_iter=10000),0.461,0.434,0.434,0.259,0.259,0.434,0,0.0,108,108.0,126,126.0,0:00:00.210943,0:00:00,

16,5,1,0.675,LinearSVC(max_iter=10000),0.461,0.434,0.434,0.259,0.259,0.434,0,0.0,93,93.0,107,107.0,0:00:00.210917,0:00:00,

16,5,1,0.65,LinearSVC(max_iter=10000),0.461,0.434,0.434,0.259,0.259,0.434,0,0.0,79,79.0,88,88.0,0:00:00.232691,0:00:00,

16,5,1,0.625,LinearSVC(max_iter=10000),0.457,0.437,0.437,0.265,0.265,0.437,0,0.0,68,68.0,74,74.0,0:00:00.184876,0:00:00,

16,5,1,0.6,LinearSVC(max_iter=10000),0.443,0.417,0.417,0.242,0.242,0.417,0,0.0,54,54.0,60,60.0,0:00:00.135387,0:00:00,

16,5,1,0.575,LinearSVC(max_iter=10000),0.436,0.42,0.42,0.195,0.195,0.42,0,0.0,31,31.0,33,33.0,0:00:00.085436,0:00:00,

16,5,1,0.55,LinearSVC(max_iter=10000),0.43,0.416,0.416,0.195,0.195,0.416,0,0.0,24,24.0,24,24.0,0:00:00.063673,0:00:00,

16,10,1,0.85,LinearSVC(max_iter=10000),0.242,0.23,0.23,0.062,0.062,0.23,0,0.0,720,720.0,2147,2147.0,0:00:00.116809,0:00:00,

16,10,1,0.8,LinearSVC(max_iter=10000),0.637,0.608,0.608,0.37,0.37,0.608,0,0.0,817,817.0,1862,1862.0,0:00:00.142898,0:00:00,

16,10,1,0.775,LinearSVC(max_iter=10000),0.642,0.611,0.611,0.381,0.381,0.611,0,0.0,844,844.0,1659,1659.0,0:00:00.175879,0:00:00,

16,10,1,0.75,LinearSVC(max_iter=10000),0.633,0.605,0.605,0.375,0.375,0.605,0,0.0,844,844.0,1575,1575.0,0:00:00.179950,0:00:00,

16,10,1,0.725,LinearSVC(max_iter=10000),0.691,0.663,0.663,0.507,0.507,0.663,0,0.0,793,793.0,1335,1335.0,0:00:00.225748,0:00:00,

16,10,1,0.7,LinearSVC(max_iter=10000),0.507,0.482,0.482,0.362,0.362,0.482,0,0.0,781,781.0,1227,1227.0,0:00:00.254310,0:00:00,

16,10,1,0.675,LinearSVC(max_iter=10000),0.474,0.444,0.444,0.285,0.285,0.444,0,0.0,769,769.0,1135,1135.0,0:00:00.261365,0:00:00,

16,10,1,0.65,LinearSVC(max_iter=10000),0.474,0.444,0.444,0.285,0.285,0.444,0,0.0,651,651.0,864,864.0,0:00:00.247643,0:00:00,

16,10,1,0.625,LinearSVC(max_iter=10000),0.47,0.442,0.442,0.274,0.274,0.442,0,0.0,623,623.0,795,795.0,0:00:00.220488,0:00:00,

16,10,1,0.6,LinearSVC(max_iter=10000),0.466,0.438,0.438,0.276,0.276,0.438,0,0.0,565,565.0,686,686.0,0:00:00.201276,0:00:00,

16,10,1,0.575,LinearSVC(max_iter=10000),0.455,0.433,0.433,0.278,0.278,0.433,0,0.0,444,444.0,506,506.0,0:00:00.143743,0:00:00,

16,10,1,0.55,LinearSVC(max_iter=10000),0.412,0.388,0.388,0.186,0.186,0.388,0,0.0,359,359.0,397,397.0,0:00:00.094450,0:00:00,

32,5,1,0.85,LinearSVC(max_iter=10000),0.242,0.23,0.23,0.062,0.062,0.23,0,0.0,193,193.0,598,598.0,0:00:00.064392,0:00:00,

32,5,1,0.8,LinearSVC(max_iter=10000),0.637,0.604,0.604,0.392,0.392,0.604,0,0.0,233,233.0,487,487.0,0:00:00.131045,0:00:00,

32,5,1,0.775,LinearSVC(max_iter=10000),0.716,0.676,0.676,0.537,0.537,0.676,0,0.0,240,240.0,435,435.0,0:00:00.166786,0:00:00,

32,5,1,0.75,LinearSVC(max_iter=10000),0.676,0.638,0.638,0.463,0.463,0.638,0,0.0,245,245.0,377,377.0,0:00:00.335267,0:00:00,

32,5,1,0.725,LinearSVC(max_iter=10000),0.671,0.626,0.626,0.46,0.46,0.626,0,0.0,229,229.0,317,317.0,0:00:00.389491,0:00:00,

32,5,1,0.7,LinearSVC(max_iter=10000),0.488,0.447,0.447,0.316,0.316,0.447,0,0.0,214,214.0,276,276.0,0:00:00.497687,0:00:00,

32,5,1,0.675,LinearSVC(max_iter=10000),0.488,0.447,0.447,0.316,0.316,0.447,0,0.0,193,193.0,238,238.0,0:00:00.437405,0:00:00,

32,5,1,0.65,LinearSVC(max_iter=10000),0.48,0.446,0.446,0.307,0.307,0.446,0,0.0,171,171.0,205,205.0,0:00:00.354134,0:00:00,

32,5,1,0.625,LinearSVC(max_iter=10000),0.477,0.448,0.448,0.303,0.303,0.448,0,0.0,145,145.0,164,164.0,0:00:00.261262,0:00:00,

32,5,1,0.6,LinearSVC(max_iter=10000),0.473,0.449,0.449,0.307,0.307,0.449,0,0.0,114,114.0,124,124.0,0:00:00.215960,0:00:00,

32,5,1,0.575,LinearSVC(max_iter=10000),0.464,0.438,0.438,0.287,0.287,0.438,0,0.0,74,74.0,81,81.0,0:00:00.150582,0:00:00,

32,5,1,0.55,LinearSVC(max_iter=10000),0.439,0.414,0.414,0.215,0.215,0.414,0,0.0,54,54.0,56,56.0,0:00:00.090405,0:00:00,

32,10,1,0.85,LinearSVC(max_iter=10000),0.437,0.408,0.408,0.209,0.209,0.408,0,0.0,1407,1407.0,4283,4283.0,0:00:00.222168,0:00:00,

32,10,1,0.8,LinearSVC(max_iter=10000),0.683,0.644,0.644,0.46,0.46,0.644,0,0.0,1581,1581.0,3742,3742.0,0:00:00.267618,0:00:00,

32,10,1,0.775,LinearSVC(max_iter=10000),0.655,0.62,0.62,0.394,0.394,0.62,0,0.0,1630,1630.0,3310,3310.0,0:00:00.361780,0:00:00,

32,10,1,0.75,LinearSVC(max_iter=10000),0.656,0.624,0.624,0.417,0.417,0.624,0,0.0,1664,1664.0,3138,3138.0,0:00:00.435039,0:00:00,

32,10,1,0.725,LinearSVC(max_iter=10000),0.649,0.612,0.612,0.41,0.41,0.612,0,0.0,1571,1571.0,2648,2648.0,0:00:00.471567,0:00:00,

32,10,1,0.7,LinearSVC(max_iter=10000),0.515,0.491,0.491,0.402,0.402,0.491,0,0.0,1556,1556.0,2398,2398.0,0:00:00.635812,0:00:00,

32,10,1,0.675,LinearSVC(max_iter=10000),0.473,0.44,0.44,0.302,0.302,0.44,0,0.0,1514,1514.0,2207,2207.0,0:00:00.448435,0:00:00,

32,10,1,0.65,LinearSVC(max_iter=10000),0.473,0.44,0.44,0.302,0.302,0.44,0,0.0,1216,1216.0,1617,1617.0,0:00:00.564918,0:00:00,

32,10,1,0.625,LinearSVC(max_iter=10000),0.465,0.436,0.436,0.296,0.296,0.436,0,0.0,1149,1149.0,1471,1471.0,0:00:00.363041,0:00:00,

32,10,1,0.6,LinearSVC(max_iter=10000),0.451,0.428,0.428,0.253,0.253,0.428,0,0.0,1047,1047.0,1292,1292.0,0:00:00.311739,0:00:00,

32,10,1,0.575,LinearSVC(max_iter=10000),0.445,0.418,0.418,0.228,0.228,0.418,0,0.0,867,867.0,984,984.0,0:00:00.183147,0:00:00,

32,10,1,0.55,LinearSVC(max_iter=10000),0.432,0.418,0.418,0.196,0.196,0.419,0,0.0,716,716.0,782,782.0,0:00:00.106389,0:00:00,

64,5,1,1.0,LogisticRegression(max_iter=10000),0.996,0.872,0.0,0.852,0.0,0.872,0,0,954,1.0,2746,1.0,0:01:30.813602,0:00:00,

64,5,1,0.95,LogisticRegression(max_iter=10000),0.994,0.873,0.001,0.854,0.002,0.873,0,0,965,1.012,2330,0.849,0:01:27.172179,0:00:00,

64,5,1,0.9,LogisticRegression(max_iter=10000),0.992,0.874,0.002,0.854,0.002,0.874,0,0,987,1.035,2040,0.743,0:01:29.927849,0:00:00,

64,5,1,0.85,LogisticRegression(max_iter=10000),0.99,0.872,-0.0,0.854,0.002,0.872,0,0,963,1.009,1779,0.648,0:00:54.687230,0:00:00,

64,5,1,0.8,LogisticRegression(max_iter=10000),0.986,0.87,-0.001,0.852,-0.0,0.87,0,0,962,1.008,1464,0.533,0:00:50.638473,0:00:00,

64,5,1,0.75,LogisticRegression(max_iter=10000),0.981,0.866,-0.006,0.846,-0.006,0.866,0,0,870,0.912,1123,0.409,0:00:40.959739,0:00:00,

64,5,1,0.7,LogisticRegression(max_iter=10000),0.967,0.868,-0.004,0.848,-0.004,0.868,0,0,723,0.758,832,0.303,0:00:29.063583,0:00:00,

64,5,1,0.65,LogisticRegression(max_iter=10000),0.956,0.868,-0.004,0.847,-0.006,0.868,0,0,579,0.607,632,0.23,0:00:21.335841,0:00:00,

64,5,1,0.6,LogisticRegression(max_iter=10000),0.939,0.864,-0.008,0.841,-0.011,0.864,0,0,389,0.408,417,0.152,0:00:13.055973,0:00:00,

64,10,1,1.0,LogisticRegression(max_iter=10000),1.0,0.872,0.0,0.856,0.0,0.872,0,0,2144,1.0,15160,1.0,0:03:20.474707,0:00:00,

64,10,1,0.95,LogisticRegression(max_iter=10000),1.0,0.874,0.002,0.858,0.002,0.874,0,0,3446,1.607,13262,0.875,0:07:01.291720,0:00:00,

64,10,1,0.9,LogisticRegression(max_iter=10000),1.0,0.876,0.003,0.86,0.004,0.876,0,0,4263,1.988,11735,0.774,0:02:52.904186,0:00:00,

64,10,1,0.85,LogisticRegression(max_iter=10000),1.0,0.873,0.001,0.858,0.002,0.873,0,0,4767,2.223,10272,0.678,0:06:17.048952,0:00:00,

64,10,1,0.8,LogisticRegression(max_iter=10000),1.0,0.869,-0.003,0.852,-0.004,0.869,0,0,5039,2.35,9110,0.601,0:05:10.141487,0:00:00,

64,10,1,0.75,LogisticRegression(max_iter=10000),1.0,0.87,-0.001,0.854,-0.002,0.87,0,0,5044,2.353,7857,0.518,0:05:31.576613,0:00:00,

64,10,1,0.7,LogisticRegression(max_iter=10000),1.0,0.871,-0.001,0.855,-0.001,0.871,0,0,4679,2.182,6347,0.419,0:03:41.579123,0:00:00,

64,10,1,0.65,LogisticRegression(max_iter=10000),1.0,0.869,-0.003,0.852,-0.004,0.869,0,0,3770,1.758,4529,0.299,0:02:47.971822,0:00:00,

64,10,1,0.6,LogisticRegression(max_iter=10000),1.0,0.87,-0.001,0.854,-0.002,0.87,0,0,3397,1.584,3862,0.255,0:02:35.108002,0:00:00,

64,15,1,1.0,LogisticRegression(max_iter=10000),1.0,0.874,0.0,0.858,0.0,0.874,0,0,2225,1.0,23084,1.0,0:10:33.263046,0:00:00,

64,15,1,0.95,LogisticRegression(max_iter=10000),1.0,0.876,0.002,0.859,0.001,0.876,0,0,4384,1.97,20422,0.885,0:08:47.884646,0:00:00,

64,15,1,0.9,LogisticRegression(max_iter=10000),1.0,0.876,0.002,0.86,0.002,0.876,0,0,5676,2.551,18179,0.788,0:04:11.610633,0:00:00,

64,15,1,0.85,LogisticRegression(max_iter=10000),1.0,0.877,0.003,0.861,0.003,0.877,0,0,6528,2.934,15920,0.69,0:07:45.043059,0:00:00,

64,15,1,0.8,LogisticRegression(max_iter=10000),1.0,0.875,0.001,0.859,0.001,0.875,0,0,7069,3.177,14189,0.615,0:09:41.855461,0:00:00,

64,15,1,0.75,LogisticRegression(max_iter=10000),1.0,0.87,-0.004,0.854,-0.004,0.87,0,0,7254,3.26,12312,0.533,0:07:19.526431,0:00:00,

