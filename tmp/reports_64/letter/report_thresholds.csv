Forest Size, Forest Depth, Patterns threshold, Edges Threshold, Learner, Train Accuracy, Test Accuracy, Test Accuracy (gain), F1_macro, F1_macro (gain), F1_micro, ROC_AUC, ROC_AUC (gain), Patterns Count, Patterns Ratio, Nodes Count, Nodes Ratio, Training Time, Pruning Time

64,5,1,1.0,LogisticRegression(max_iter=10000),0.323,0.335,0.0,0.343,0.0,0.335,0,0,64,1.0,1868,1.0,0:00:36.509942,0:00:00,

64,5,1,0.95,LogisticRegression(max_iter=10000),0.249,0.261,-0.073,0.229,-0.115,0.261,0,0,128,2.0,1718,0.92,0:00:34.758383,0:00:00,

64,5,1,0.9,LogisticRegression(max_iter=10000),0.276,0.29,-0.045,0.246,-0.097,0.29,0,0,252,3.938,1517,0.812,0:00:44.121514,0:00:00,

64,5,1,0.85,LogisticRegression(max_iter=10000),0.329,0.342,0.007,0.285,-0.058,0.342,0,0,341,5.328,1336,0.715,0:01:08.890544,0:00:00,

64,5,1,0.8,LogisticRegression(max_iter=10000),0.398,0.41,0.076,0.378,0.035,0.41,0,0,402,6.281,1131,0.605,0:00:55.953187,0:00:00,

64,5,1,0.75,LogisticRegression(max_iter=10000),0.312,0.321,-0.013,0.273,-0.07,0.321,0,0,422,6.594,916,0.49,0:00:44.748056,0:00:00,

64,5,1,0.7,LogisticRegression(max_iter=10000),0.307,0.314,-0.021,0.276,-0.067,0.314,0,0,414,6.469,732,0.392,0:00:39.958944,0:00:00,

64,5,1,0.65,LogisticRegression(max_iter=10000),0.316,0.33,-0.004,0.28,-0.063,0.33,0,0,353,5.516,518,0.277,0:00:32.532368,0:00:00,

64,5,1,0.6,LogisticRegression(max_iter=10000),0.197,0.204,-0.131,0.11,-0.234,0.204,0,0,274,4.281,348,0.186,0:00:16.252206,0:00:00,

64,10,1,1.0,LogisticRegression(max_iter=10000),0.139,0.144,0.0,0.136,0.0,0.144,0,0,64,1.0,24039,1.0,0:05:44.388806,0:00:00,

64,10,1,0.95,LogisticRegression(max_iter=10000),0.041,0.041,-0.103,0.003,-0.133,0.041,0,0,1421,22.203,21606,0.899,0:00:22.751398,0:00:00,

64,10,1,0.9,LogisticRegression(max_iter=10000),0.108,0.106,-0.038,0.05,-0.086,0.106,0,0,2862,44.719,19174,0.798,0:05:38.970914,0:00:00,

64,10,1,0.85,LogisticRegression(max_iter=10000),0.26,0.261,0.117,0.212,0.076,0.261,0,0,4043,63.172,16613,0.691,0:11:56.776563,0:00:00,

64,10,1,0.8,LogisticRegression(max_iter=10000),0.312,0.322,0.178,0.281,0.146,0.322,0,0,4883,76.297,14475,0.602,0:10:11.052600,0:00:00,

64,10,1,0.75,LogisticRegression(max_iter=10000),0.286,0.292,0.148,0.243,0.108,0.292,0,0,5319,83.109,12152,0.506,0:04:12.295149,0:00:00,

64,10,1,0.7,LogisticRegression(max_iter=10000),0.356,0.368,0.224,0.329,0.193,0.368,0,0,5256,82.125,9525,0.396,0:05:54.093164,0:00:00,

64,10,1,0.65,LogisticRegression(max_iter=10000),0.234,0.241,0.097,0.16,0.024,0.241,0,0,4484,70.062,6697,0.279,0:03:36.755933,0:00:00,

64,10,1,0.6,LogisticRegression(max_iter=10000),0.197,0.204,0.06,0.11,-0.026,0.204,0,0,3747,58.547,4881,0.203,0:02:09.813414,0:00:00,

64,15,1,1.0,LogisticRegression(max_iter=10000),0.129,0.134,0.0,0.12,0.0,0.134,0,0,64,1.0,83032,1.0,0:52:17.324192,0:00:00,

64,15,1,0.95,LogisticRegression(max_iter=10000),0.041,0.041,-0.093,0.003,-0.117,0.041,0,0,3991,62.359,77224,0.93,0:00:48.345574,0:00:00,

64,15,1,0.9,LogisticRegression(max_iter=10000),0.071,0.075,-0.059,0.011,-0.109,0.075,0,0,8671,135.484,69971,0.843,0:06:00.325353,0:00:00,

64,15,1,0.85,LogisticRegression(max_iter=10000),0.164,0.168,0.034,0.104,-0.016,0.168,0,0,13218,206.531,61477,0.74,0:25:29.770775,0:00:00,

64,15,1,0.8,LogisticRegression(max_iter=10000),0.252,0.258,0.124,0.188,0.068,0.258,0,0,16393,256.141,54690,0.659,0:17:40.067050,0:00:00,

64,15,1,0.75,LogisticRegression(max_iter=10000),0.404,0.409,0.275,0.38,0.26,0.409,0,0,18655,291.484,47021,0.566,0:20:01.679845,0:00:00,

64,15,1,0.7,LogisticRegression(max_iter=10000),0.427,0.434,0.3,0.416,0.296,0.434,0,0,19362,302.531,37370,0.45,0:31:22.817384,0:00:00,

64,15,1,0.65,LogisticRegression(max_iter=10000),0.297,0.296,0.163,0.254,0.134,0.296,0,0,16949,264.828,25615,0.308,0:15:01.694329,0:00:00,

64,15,1,0.6,LogisticRegression(max_iter=10000),0.238,0.239,0.105,0.169,0.049,0.239,0,0,15342,239.719,20464,0.246,0:08:31.516423,0:00:00,

