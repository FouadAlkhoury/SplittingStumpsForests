Forest Size, Forest Depth, Patterns threshold, Edges Threshold, Learner, Train Accuracy, Test Accuracy, Test Accuracy (gain), F1_macro, F1_macro (gain), F1_micro, ROC_AUC, ROC_AUC (gain), Patterns Count, Patterns Ratio, Nodes Count, Nodes Ratio, Training Time, Pruning Time

64,5,1,1.0,LogisticRegression(max_iter=10000),0.919,0.901,0.0,0.908,0.0,0.901,0,0,476,1.0,476,1.0,0:00:55.100961,0:00:00,

64,5,1,0.95,LogisticRegression(max_iter=10000),0.913,0.897,-0.004,0.903,-0.005,0.897,0,0,416,0.874,416,0.874,0:00:50.650627,0:00:00,

64,5,1,0.9,LogisticRegression(max_iter=10000),0.91,0.896,-0.005,0.902,-0.006,0.896,0,0,344,0.723,344,0.723,0:00:35.729830,0:00:00,

64,5,1,0.85,LogisticRegression(max_iter=10000),0.897,0.88,-0.021,0.878,-0.03,0.88,0,0,294,0.618,294,0.618,0:00:30.572457,0:00:00,

64,5,1,0.8,LogisticRegression(max_iter=10000),0.895,0.879,-0.022,0.877,-0.031,0.879,0,0,229,0.481,229,0.481,0:00:22.877209,0:00:00,

64,5,1,0.75,LogisticRegression(max_iter=10000),0.892,0.88,-0.021,0.878,-0.03,0.88,0,0,181,0.38,181,0.38,0:00:15.619777,0:00:00,

64,5,1,0.7,LogisticRegression(max_iter=10000),0.891,0.88,-0.021,0.878,-0.03,0.88,0,0,147,0.309,147,0.309,0:00:13.370241,0:00:00,

64,5,1,0.65,LogisticRegression(max_iter=10000),0.861,0.853,-0.048,0.821,-0.087,0.853,0,0,111,0.233,111,0.233,0:00:10.194977,0:00:00,

64,5,1,0.6,LogisticRegression(max_iter=10000),0.822,0.819,-0.082,0.681,-0.227,0.819,0,0,81,0.17,81,0.17,0:00:08.627744,0:00:00,

64,10,1,1.0,LogisticRegression(max_iter=10000),0.973,0.904,0.0,0.916,0.0,0.904,0,0,2288,1.0,2288,1.0,0:06:56.454111,0:00:00,

64,10,1,0.95,LogisticRegression(max_iter=10000),0.971,0.903,-0.001,0.915,-0.0,0.903,0,0,2082,0.91,2082,0.91,0:06:52.558717,0:00:00,

64,10,1,0.9,LogisticRegression(max_iter=10000),0.968,0.905,0.001,0.917,0.002,0.905,0,0,1879,0.821,1879,0.821,0:05:18.694197,0:00:00,

64,10,1,0.85,LogisticRegression(max_iter=10000),0.965,0.904,0.0,0.917,0.001,0.904,0,0,1664,0.727,1664,0.727,0:04:51.114040,0:00:00,

64,10,1,0.8,LogisticRegression(max_iter=10000),0.961,0.906,0.002,0.917,0.002,0.906,0,0,1510,0.66,1510,0.66,0:04:51.231913,0:00:00,

64,10,1,0.75,LogisticRegression(max_iter=10000),0.958,0.909,0.005,0.92,0.005,0.909,0,0,1336,0.584,1336,0.584,0:04:02.250173,0:00:00,

64,10,1,0.7,LogisticRegression(max_iter=10000),0.952,0.905,0.001,0.918,0.002,0.905,0,0,1117,0.488,1117,0.488,0:03:07.956988,0:00:00,

64,10,1,0.65,LogisticRegression(max_iter=10000),0.946,0.906,0.002,0.917,0.001,0.906,0,0,856,0.374,856,0.374,0:02:21.205424,0:00:00,

64,10,1,0.6,LogisticRegression(max_iter=10000),0.94,0.908,0.004,0.919,0.004,0.908,0,0,732,0.32,732,0.32,0:01:29.063957,0:00:00,

64,15,1,1.0,LogisticRegression(max_iter=10000),0.989,0.903,0.0,0.915,0.0,0.903,0,0,4108,1.0,4108,1.0,0:15:55.076873,0:00:00,

64,15,1,0.95,LogisticRegression(max_iter=10000),0.988,0.901,-0.001,0.913,-0.002,0.901,0,0,3768,0.917,3768,0.917,0:13:52.350766,0:00:00,

64,15,1,0.9,LogisticRegression(max_iter=10000),0.986,0.901,-0.001,0.913,-0.002,0.901,0,0,3451,0.84,3451,0.84,0:12:08.810676,0:00:00,

64,15,1,0.85,LogisticRegression(max_iter=10000),0.984,0.901,-0.001,0.912,-0.002,0.901,0,0,3125,0.761,3125,0.761,0:10:12.800310,0:00:00,

64,15,1,0.8,LogisticRegression(max_iter=10000),0.981,0.9,-0.003,0.912,-0.002,0.9,0,0,2852,0.694,2852,0.694,0:52:58.630106,0:00:00,

64,15,1,0.75,LogisticRegression(max_iter=10000),0.977,0.9,-0.003,0.912,-0.002,0.9,0,0,2557,0.622,2557,0.622,0:06:36.759491,0:00:00,

64,15,1,0.7,LogisticRegression(max_iter=10000),0.973,0.9,-0.003,0.911,-0.003,0.9,0,0,2163,0.527,2163,0.527,0:05:21.765748,0:00:00,

64,15,1,0.65,LogisticRegression(max_iter=10000),0.964,0.908,0.005,0.918,0.003,0.908,0,0,1583,0.385,1583,0.385,0:20:26.100625,0:00:00,

64,15,1,0.6,LogisticRegression(max_iter=10000),0.959,0.903,0.0,0.914,-0.001,0.903,0,0,1413,0.344,1413,0.344,0:03:24.045990,0:00:00,

Forest Size, Forest Depth, Patterns threshold, Edges Threshold, Learner, Train Accuracy, Test Accuracy, Test Accuracy (gain), F1_macro, F1_macro (gain), F1_micro, ROC_AUC, ROC_AUC (gain), Patterns Count, Patterns Ratio, Nodes Count, Nodes Ratio, Training Time, Pruning Time

16,5,1,1.0,LogisticRegression(max_iter=10000),0.887,0.879,0.0,0.875,0.0,0.879,0,0,175,1.0,175,1.0,0:00:16.367461,0:00:00,

16,5,1,0.95,LogisticRegression(max_iter=10000),0.887,0.879,-0.0,0.875,-0.0,0.879,0,0,158,0.903,158,0.903,0:00:21.269771,0:00:00,

16,5,1,0.9,LogisticRegression(max_iter=10000),0.881,0.873,-0.006,0.867,-0.008,0.873,0,0,133,0.76,133,0.76,0:00:12.256867,0:00:00,

16,5,1,0.85,LogisticRegression(max_iter=10000),0.874,0.869,-0.01,0.861,-0.015,0.869,0,0,110,0.629,110,0.629,0:00:09.558971,0:00:00,

16,5,1,0.8,LogisticRegression(max_iter=10000),0.873,0.867,-0.012,0.858,-0.017,0.867,0,0,88,0.503,88,0.503,0:00:09.637527,0:00:00,

16,5,1,0.75,LogisticRegression(max_iter=10000),0.868,0.863,-0.016,0.849,-0.026,0.863,0,0,72,0.411,72,0.411,0:00:06.871358,0:00:00,

16,5,1,0.7,LogisticRegression(max_iter=10000),0.831,0.826,-0.053,0.701,-0.175,0.826,0,0,56,0.32,56,0.32,0:00:05.977563,0:00:00,

16,5,1,0.65,LogisticRegression(max_iter=10000),0.8,0.797,-0.082,0.639,-0.236,0.797,0,0,48,0.274,48,0.274,0:00:05.874775,0:00:00,

16,5,1,0.6,LogisticRegression(max_iter=10000),0.793,0.79,-0.089,0.634,-0.241,0.79,0,0,35,0.2,35,0.2,0:00:07.784915,0:00:00,

16,10,1,1.0,LogisticRegression(max_iter=10000),0.943,0.907,0.0,0.917,0.0,0.907,0,0,872,1.0,872,1.0,0:01:49.896299,0:00:00,

16,10,1,0.95,LogisticRegression(max_iter=10000),0.941,0.901,-0.006,0.911,-0.006,0.901,0,0,783,0.898,783,0.898,0:01:46.761586,0:00:00,

16,10,1,0.9,LogisticRegression(max_iter=10000),0.938,0.903,-0.004,0.912,-0.004,0.903,0,0,695,0.797,695,0.797,0:01:12.703638,0:00:00,

16,10,1,0.85,LogisticRegression(max_iter=10000),0.936,0.905,-0.001,0.915,-0.001,0.905,0,0,607,0.696,607,0.696,0:01:08.679014,0:00:00,

16,10,1,0.8,LogisticRegression(max_iter=10000),0.935,0.903,-0.003,0.913,-0.003,0.903,0,0,536,0.615,536,0.615,0:00:57.538129,0:00:00,

16,10,1,0.75,LogisticRegression(max_iter=10000),0.93,0.903,-0.003,0.914,-0.003,0.903,0,0,462,0.53,462,0.53,0:00:53.258398,0:00:00,

16,10,1,0.7,LogisticRegression(max_iter=10000),0.928,0.905,-0.001,0.916,-0.001,0.905,0,0,380,0.436,380,0.436,0:00:41.370353,0:00:00,

16,10,1,0.65,LogisticRegression(max_iter=10000),0.92,0.903,-0.004,0.913,-0.004,0.903,0,0,286,0.328,286,0.328,0:00:25.300250,0:00:00,

16,10,1,0.6,LogisticRegression(max_iter=10000),0.911,0.895,-0.011,0.903,-0.014,0.895,0,0,244,0.28,244,0.28,0:00:28.895478,0:00:00,

16,15,1,1.0,LogisticRegression(max_iter=10000),0.963,0.907,0.0,0.918,0.0,0.907,0,0,1490,1.0,1490,1.0,0:04:23.658375,0:00:00,

16,15,1,0.95,LogisticRegression(max_iter=10000),0.96,0.906,-0.001,0.917,-0.001,0.906,0,0,1366,0.917,1366,0.917,0:03:53.162744,0:00:00,

16,15,1,0.9,LogisticRegression(max_iter=10000),0.958,0.908,0.001,0.919,0.0,0.908,0,0,1248,0.838,1248,0.838,0:02:56.265484,0:00:00,

16,15,1,0.85,LogisticRegression(max_iter=10000),0.955,0.907,-0.0,0.917,-0.001,0.907,0,0,1118,0.75,1118,0.75,0:02:37.146614,0:00:00,

16,15,1,0.8,LogisticRegression(max_iter=10000),0.952,0.908,0.001,0.919,0.001,0.908,0,0,1025,0.688,1025,0.688,0:02:29.320503,0:00:00,

16,15,1,0.75,LogisticRegression(max_iter=10000),0.945,0.907,-0.0,0.915,-0.004,0.907,0,0,916,0.615,916,0.615,0:02:19.866916,0:00:00,

16,15,1,0.7,LogisticRegression(max_iter=10000),0.94,0.909,0.001,0.915,-0.003,0.909,0,0,750,0.503,750,0.503,0:01:31.680035,0:00:00,

16,15,1,0.65,LogisticRegression(max_iter=10000),0.929,0.905,-0.002,0.907,-0.011,0.905,0,0,577,0.387,577,0.387,0:01:05.210792,0:00:00,

16,15,1,0.6,LogisticRegression(max_iter=10000),0.925,0.903,-0.004,0.906,-0.013,0.903,0,0,491,0.33,491,0.33,0:01:13.965362,0:00:00,

32,5,1,1.0,LogisticRegression(max_iter=10000),0.908,0.89,0.0,0.895,0.0,0.89,0,0,282,1.0,282,1.0,0:00:38.410967,0:00:00,

32,5,1,0.95,LogisticRegression(max_iter=10000),0.906,0.889,-0.001,0.892,-0.003,0.889,0,0,254,0.901,254,0.901,0:00:27.370156,0:00:00,

32,5,1,0.9,LogisticRegression(max_iter=10000),0.903,0.896,0.006,0.901,0.006,0.896,0,0,210,0.745,210,0.745,0:00:20.739215,0:00:00,

32,5,1,0.85,LogisticRegression(max_iter=10000),0.893,0.88,-0.011,0.877,-0.018,0.88,0,0,188,0.667,188,0.667,0:00:20.421182,0:00:00,

32,5,1,0.8,LogisticRegression(max_iter=10000),0.883,0.874,-0.017,0.874,-0.021,0.874,0,0,146,0.518,146,0.518,0:00:16.690379,0:00:00,

32,5,1,0.75,LogisticRegression(max_iter=10000),0.88,0.873,-0.018,0.872,-0.023,0.873,0,0,114,0.404,114,0.404,0:00:09.059381,0:00:00,

32,5,1,0.7,LogisticRegression(max_iter=10000),0.855,0.842,-0.048,0.809,-0.086,0.842,0,0,96,0.34,96,0.34,0:00:07.990386,0:00:00,

32,5,1,0.65,LogisticRegression(max_iter=10000),0.851,0.839,-0.051,0.805,-0.09,0.839,0,0,78,0.277,78,0.277,0:00:12.968001,0:00:00,

32,5,1,0.6,LogisticRegression(max_iter=10000),0.811,0.811,-0.079,0.742,-0.153,0.811,0,0,53,0.188,53,0.188,0:00:07.760325,0:00:00,

32,10,1,1.0,LogisticRegression(max_iter=10000),0.957,0.905,0.0,0.916,0.0,0.905,0,0,1415,1.0,1415,1.0,0:03:27.052075,0:00:00,

32,10,1,0.95,LogisticRegression(max_iter=10000),0.954,0.905,0.0,0.917,0.001,0.905,0,0,1289,0.911,1289,0.911,0:02:58.739119,0:00:00,

32,10,1,0.9,LogisticRegression(max_iter=10000),0.95,0.908,0.003,0.919,0.003,0.908,0,0,1133,0.801,1133,0.801,0:02:45.110627,0:00:00,

32,10,1,0.85,LogisticRegression(max_iter=10000),0.947,0.907,0.003,0.919,0.003,0.907,0,0,1003,0.709,1003,0.709,0:02:10.926975,0:00:00,

32,10,1,0.8,LogisticRegression(max_iter=10000),0.944,0.907,0.002,0.918,0.002,0.907,0,0,903,0.638,903,0.638,0:02:14.039733,0:00:00,

32,10,1,0.75,LogisticRegression(max_iter=10000),0.941,0.908,0.003,0.918,0.002,0.908,0,0,800,0.565,800,0.565,0:01:52.403822,0:00:00,

32,10,1,0.7,LogisticRegression(max_iter=10000),0.935,0.904,-0.001,0.912,-0.004,0.904,0,0,658,0.465,658,0.465,0:01:29.850792,0:00:00,

32,10,1,0.65,LogisticRegression(max_iter=10000),0.924,0.899,-0.006,0.906,-0.01,0.899,0,0,493,0.348,493,0.348,0:00:59.193936,0:00:00,

32,10,1,0.6,LogisticRegression(max_iter=10000),0.915,0.893,-0.011,0.896,-0.02,0.893,0,0,408,0.288,408,0.288,0:00:51.807921,0:00:00,

32,15,1,1.0,LogisticRegression(max_iter=10000),0.976,0.902,0.0,0.913,0.0,0.902,0,0,2457,1.0,2457,1.0,0:07:48.558363,0:00:00,

32,15,1,0.95,LogisticRegression(max_iter=10000),0.974,0.902,0.0,0.914,0.001,0.902,0,0,2269,0.923,2269,0.923,0:07:03.003327,0:00:00,

32,15,1,0.9,LogisticRegression(max_iter=10000),0.971,0.901,-0.001,0.913,-0.0,0.901,0,0,2058,0.838,2058,0.838,0:06:24.709446,0:00:00,

32,15,1,0.85,LogisticRegression(max_iter=10000),0.969,0.901,-0.001,0.913,-0.0,0.901,0,0,1857,0.756,1857,0.756,0:04:59.467072,0:00:00,

32,15,1,0.8,LogisticRegression(max_iter=10000),0.966,0.903,0.001,0.913,-0.0,0.903,0,0,1703,0.693,1703,0.693,0:04:35.779684,0:00:00,

32,15,1,0.75,LogisticRegression(max_iter=10000),0.963,0.901,-0.0,0.912,-0.002,0.901,0,0,1523,0.62,1523,0.62,0:03:47.806158,0:00:00,

32,15,1,0.7,LogisticRegression(max_iter=10000),0.958,0.905,0.003,0.915,0.002,0.905,0,0,1283,0.522,1283,0.522,0:02:57.865605,0:00:00,

32,15,1,0.65,LogisticRegression(max_iter=10000),0.95,0.907,0.005,0.918,0.004,0.907,0,0,960,0.391,960,0.391,0:01:59.696618,0:00:00,

32,15,1,0.6,LogisticRegression(max_iter=10000),0.945,0.906,0.004,0.918,0.004,0.906,0,0,854,0.348,854,0.348,0:01:43.037269,0:00:00,

64,5,1,1.0,LogisticRegression(max_iter=10000),0.92,0.897,0.0,0.903,0.0,0.897,0,0,473,1.0,473,1.0,0:00:49.197412,0:00:00,

64,5,1,0.95,LogisticRegression(max_iter=10000),0.916,0.897,0.0,0.903,0.0,0.897,0,0,408,0.863,408,0.863,0:00:37.939055,0:00:00,

64,5,1,0.9,LogisticRegression(max_iter=10000),0.912,0.898,0.002,0.905,0.002,0.898,0,0,345,0.729,345,0.729,0:00:30.498930,0:00:00,

64,5,1,0.85,LogisticRegression(max_iter=10000),0.896,0.882,-0.015,0.881,-0.022,0.882,0,0,299,0.632,299,0.632,0:00:28.512754,0:00:00,

64,5,1,0.8,LogisticRegression(max_iter=10000),0.893,0.873,-0.024,0.87,-0.034,0.873,0,0,252,0.533,252,0.533,0:00:24.904031,0:00:00,

64,5,1,0.75,LogisticRegression(max_iter=10000),0.889,0.875,-0.021,0.872,-0.031,0.875,0,0,200,0.423,200,0.423,0:00:18.055277,0:00:00,

64,5,1,0.7,LogisticRegression(max_iter=10000),0.887,0.872,-0.025,0.869,-0.034,0.872,0,0,158,0.334,158,0.334,0:00:12.630015,0:00:00,

64,5,1,0.65,LogisticRegression(max_iter=10000),0.844,0.834,-0.063,0.712,-0.192,0.834,0,0,121,0.256,121,0.256,0:00:10.544732,0:00:00,

64,5,1,0.6,LogisticRegression(max_iter=10000),0.843,0.831,-0.065,0.709,-0.194,0.831,0,0,89,0.188,89,0.188,0:00:08.373590,0:00:00,

64,10,1,1.0,LogisticRegression(max_iter=10000),0.974,0.906,0.0,0.918,0.0,0.906,0,0,2301,1.0,2301,1.0,0:06:40.495287,0:00:00,

64,10,1,0.95,LogisticRegression(max_iter=10000),0.971,0.907,0.001,0.919,0.001,0.907,0,0,2072,0.9,2072,0.9,0:05:11.856023,0:00:00,

64,10,1,0.9,LogisticRegression(max_iter=10000),0.968,0.907,0.001,0.919,0.001,0.907,0,0,1851,0.804,1851,0.804,0:04:37.558365,0:00:00,

64,10,1,0.85,LogisticRegression(max_iter=10000),0.963,0.911,0.004,0.923,0.004,0.911,0,0,1672,0.727,1672,0.727,0:03:55.664003,0:00:00,

64,10,1,0.8,LogisticRegression(max_iter=10000),0.962,0.912,0.006,0.923,0.005,0.912,0,0,1508,0.655,1508,0.655,0:03:41.817989,0:00:00,

64,10,1,0.75,LogisticRegression(max_iter=10000),0.959,0.908,0.001,0.919,0.0,0.908,0,0,1323,0.575,1323,0.575,0:03:05.761222,0:00:00,

64,10,1,0.7,LogisticRegression(max_iter=10000),0.953,0.911,0.005,0.922,0.004,0.911,0,0,1117,0.485,1117,0.485,0:02:32.058841,0:00:00,

64,10,1,0.65,LogisticRegression(max_iter=10000),0.945,0.914,0.008,0.923,0.005,0.914,0,0,822,0.357,822,0.357,0:01:30.715198,0:00:00,

64,10,1,0.6,LogisticRegression(max_iter=10000),0.941,0.913,0.007,0.922,0.004,0.913,0,0,694,0.302,694,0.302,0:01:15.915074,0:00:00,

64,15,1,1.0,LogisticRegression(max_iter=10000),0.989,0.904,0.0,0.916,0.0,0.904,0,0,4152,1.0,4152,1.0,0:14:06.432856,0:00:00,

64,15,1,0.95,LogisticRegression(max_iter=10000),0.987,0.903,-0.0,0.915,-0.001,0.903,0,0,3858,0.929,3858,0.929,0:14:05.515302,0:00:00,

64,15,1,0.9,LogisticRegression(max_iter=10000),0.986,0.901,-0.002,0.914,-0.002,0.901,0,0,3535,0.851,3535,0.851,0:12:15.182806,0:00:00,

64,15,1,0.85,LogisticRegression(max_iter=10000),0.983,0.904,0.0,0.915,-0.001,0.904,0,0,3179,0.766,3179,0.766,0:11:40.245521,0:00:00,

64,15,1,0.8,LogisticRegression(max_iter=10000),0.981,0.903,-0.001,0.915,-0.001,0.903,0,0,2901,0.699,2901,0.699,0:09:05.082237,0:00:00,

64,15,1,0.75,LogisticRegression(max_iter=10000),0.979,0.904,0.001,0.916,0.0,0.904,0,0,2631,0.634,2631,0.634,0:07:40.380715,0:00:00,

64,15,1,0.7,LogisticRegression(max_iter=10000),0.973,0.906,0.003,0.917,0.002,0.906,0,0,2219,0.534,2219,0.534,0:05:42.883262,0:00:00,

64,15,1,0.65,LogisticRegression(max_iter=10000),0.962,0.907,-0.093,0.918,-0.082,0.907,0,-1.0,1649,1649.0,1649,1649.0,0:03:19.147150,0:00:00,

64,15,1,0.6,LogisticRegression(max_iter=10000),0.959,0.907,-0.093,0.917,-0.083,0.907,0,-1.0,1470,1470.0,1470,1470.0,0:03:45.004800,0:00:00,

16,5,1,0.55,LogisticRegression(max_iter=10000),0.675,0.673,-0.327,0.502,-0.498,0.673,0,-1.0,18,18.0,18,18.0,0:00:01.915253,0:00:00,

16,10,1,0.55,LogisticRegression(max_iter=10000),0.905,0.893,-0.107,0.897,-0.103,0.893,0,-1.0,160,160.0,160,160.0,0:00:17.785713,0:00:00,

16,15,1,0.55,LogisticRegression(max_iter=10000),0.919,0.903,-0.097,0.904,-0.096,0.903,0,-1.0,362,362.0,362,362.0,0:00:39.209947,0:00:00,

32,5,1,0.55,LogisticRegression(max_iter=10000),0.731,0.731,-0.269,0.579,-0.421,0.731,0,-1.0,33,33.0,33,33.0,0:00:06.602095,0:00:00,

32,10,1,0.55,LogisticRegression(max_iter=10000),0.904,0.885,-0.115,0.884,-0.116,0.885,0,-1.0,279,279.0,279,279.0,0:00:32.611063,0:00:00,

32,15,1,0.55,LogisticRegression(max_iter=10000),0.936,0.906,-0.094,0.915,-0.085,0.906,0,-1.0,628,628.0,628,628.0,0:01:12.128150,0:00:00,

64,5,1,0.55,LogisticRegression(max_iter=10000),0.806,0.802,-0.198,0.657,-0.343,0.802,0,-1.0,48,48.0,48,48.0,0:00:05.922353,0:00:00,

64,10,1,0.55,LogisticRegression(max_iter=10000),0.932,0.912,-0.088,0.922,-0.078,0.912,0,-1.0,493,493.0,493,493.0,0:00:59.340638,0:00:00,

64,15,1,0.55,LogisticRegression(max_iter=10000),0.949,0.907,-0.093,0.917,-0.083,0.907,0,-1.0,1109,1109.0,1109,1109.0,0:03:13.464260,0:00:00,

